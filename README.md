# ğŸ½ï¸ Restaurant Object Detection with YOLOv11

> **ğŸ“– README Languages / Ğ¯Ğ·Ñ‹ĞºĞ¸ README**  
> This README is available in two languages:  
> â€¢ [ğŸ‡·ğŸ‡º Russian Version](#russian-version) (Ğ ÑƒÑÑĞºĞ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)  
> â€¢ [ğŸ‡ºğŸ‡¸ English Version](#english-version) (English Ğ²ĞµÑ€ÑĞ¸Ñ)

---

## ğŸ› ï¸ **Technology Stack**

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-27338e?style=for-the-badge&logo=OpenCV&logoColor=white)
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white)
![Ultralytics](https://img.shields.io/badge/YOLOv11-00FFFF?style=for-the-badge&logo=yolo&logoColor=black)

![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge&logo=python&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)

</div>

---

# Russian Version

## ğŸ§  ĞŸÑ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ² Ñ€ĞµÑÑ‚Ğ¾Ñ€Ğ°Ğ½Ğ°Ñ…

**Ğ’Ñ‹ÑĞ¾ĞºĞ¾Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ YOLOv11 Ğ´Ğ»Ñ Ñ€ĞµÑÑ‚Ğ¾Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¹ ÑÑ€ĞµĞ´Ñ‹**

[![GitHub](https://img.shields.io/badge/GitHub-amir2628-181717?style=flat-square&logo=github)](https://github.com/amir2628/restaurant-object-detection)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-00FFFF?style=flat-square)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

## ğŸ“‹ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

ĞŸÑ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ², ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ°Ñ Ğ´Ğ»Ñ Ñ€ĞµÑÑ‚Ğ¾Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¹ ÑÑ€ĞµĞ´Ñ‹. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ YOLOv11 Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: Ğ¾Ñ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.

### ğŸ¯ ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸

- **ğŸ¤– ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ** Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
- **ğŸ¯ Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ** - mAP@0.5: 79.7%
- **âš¡ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ** - ~2ms Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
- **ğŸ”§ Production-ready** - Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğº Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ñ
- **ğŸ“Š Comprehensive Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³** - Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°

### ğŸ½ï¸ Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹

- ğŸ‘¥ **Ğ›ÑĞ´Ğ¸** (Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ», Ğ¿Ğ¾ÑĞµÑ‚Ğ¸Ñ‚ĞµĞ»Ğ¸)
- ğŸª‘ **ĞœĞµĞ±ĞµĞ»ÑŒ** (ÑÑ‚Ğ¾Ğ»Ñ‹, ÑÑ‚ÑƒĞ»ÑŒÑ)
- ğŸ½ï¸ **ĞŸĞ¾ÑÑƒĞ´Ğ°** (Ñ‚Ğ°Ñ€ĞµĞ»ĞºĞ¸, Ñ‡Ğ°ÑˆĞºĞ¸, Ğ±Ğ¾ĞºĞ°Ğ»Ñ‹)
- ğŸ´ **ĞŸÑ€Ğ¸Ğ±Ğ¾Ñ€Ñ‹** (Ğ²Ğ¸Ğ»ĞºĞ¸, Ğ½Ğ¾Ğ¶Ğ¸, Ğ»Ğ¾Ğ¶ĞºĞ¸)
- ğŸ• **Ğ•Ğ´Ğ°** (Ğ¿Ğ¸Ñ†Ñ†Ğ°, Ñ‚Ğ¾Ñ€Ñ‚Ñ‹, Ñ„Ñ€ÑƒĞºÑ‚Ñ‹)
- ğŸ“± **ĞŸÑ€ĞµĞ´Ğ¼ĞµÑ‚Ñ‹** (Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ñ‹, Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞºĞ¸, ĞºĞ½Ğ¸Ğ³Ğ¸)

## ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
restaurant-object-detection/
â”œâ”€â”€ ğŸ“ config/
â”‚   â”œâ”€â”€ pipeline_config.json           # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°
â”‚   â””â”€â”€ model_config.yaml             # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ fix_annotations.py            # ğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹
â”‚   â”œâ”€â”€ prepare_data.py               # ğŸ“Š ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”œâ”€â”€ train_model.py                # ğŸš€ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚   â”œâ”€â”€ run_inference.py              # ğŸ¯ Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ
â”‚   â””â”€â”€ generate_final_report.py      # ğŸ“‹ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ²
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ data/                         # ĞœĞ¾Ğ´ÑƒĞ»Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”œâ”€â”€ models/                       # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ
â”‚   â”œâ”€â”€ utils/                        # Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹
â”‚   â””â”€â”€ api/                          # API Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹ÑÑ‹
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                          # Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾
â”‚   â”œâ”€â”€ processed/dataset/            # Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚
â”‚   â””â”€â”€ annotations/                  # ĞĞ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ experiments/                  # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
â”‚   â”œâ”€â”€ inference/                    # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
â”‚   â””â”€â”€ reports/                      # ĞÑ‚Ñ‡ĞµÑ‚Ñ‹
â””â”€â”€ ğŸ“„ requirements.txt               # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
```

## ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

### 1. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°

```bash
# ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ
git clone https://github.com/amir2628/restaurant-object-detection.git
cd restaurant-object-detection

# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
pip install -r requirements.txt
```

### 2. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

**âš ï¸ Ğ’ĞĞ–ĞĞ: ĞŸĞ¾Ğ¼ĞµÑÑ‚Ğ¸Ñ‚Ğµ Ğ²Ğ°ÑˆĞ¸ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ!**

```bash
# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ²Ğ¸Ğ´ĞµĞ¾ (ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚)
mkdir -p data/raw

# ĞŸĞ¾Ğ¼ĞµÑÑ‚Ğ¸Ñ‚Ğµ Ğ²Ğ°ÑˆĞ¸ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ñ€ĞµÑÑ‚Ğ¾Ñ€Ğ°Ğ½Ğ° Ğ² data/raw/
# ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹: .mp4, .avi, .mov, .mkv, .wmv
# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹:
# data/raw/
# â”œâ”€â”€ restaurant_video_1.mp4
# â”œâ”€â”€ restaurant_video_2.mp4
# â””â”€â”€ restaurant_video_3.avi
```

### 3. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ° Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ)

```bash
# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ñ… Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹
python scripts/fix_annotations.py --dataset "data/processed/dataset"

# ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğ´Ñ€Ğ¾Ğ² + Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ)
python scripts/prepare_data.py --input "data/raw" --config "config/pipeline_config.json"
```

### 4. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

```bash
# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ¼
python scripts/train_model.py --data "data/processed/dataset/dataset.yaml"

# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸ĞµĞ¹
python scripts/train_model.py --data "dataset.yaml" --config "config/train_config.json"

# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ Weights & Biases Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼
python scripts/train_model.py --data "dataset.yaml" --wandb
```

### 4. Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ

```bash
# Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑÑ…
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --input-dir "path/to/images"

# Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --video "path/to/video.mp4"

# Real-time Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --realtime --camera 0
```

### 5. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ²

```bash
# ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ
python scripts/generate_final_report.py \
  --model-path "outputs/experiments/yolo_*/weights/best.pt" \
  --dataset-dir "data/processed/dataset" \
  --experiment-dir "outputs/experiments/yolo_*" \
  --output "final_report.md" \
  --project-time 8.5
```

## ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹

### ğŸ† Ğ”Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸

| ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹ |
|---------|----------|-------------|
| **mAP@0.5** | **79.7%** | ğŸ¥‡ ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ |
| **mAP@0.5:0.95** | **74.2%** | ğŸ¥ˆ Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ |
| **Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°** | **~2ms** | âš¡ Real-time Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° |
| **Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸** | **~6MB** | ğŸ“¦ ĞšĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ğ°Ñ |
| **Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ** | **17.5 Ğ¼Ğ¸Ğ½** | ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ |

### ğŸ“ˆ ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸

- **ğŸ¤– Ensemble Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ** - Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ 3 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (YOLOv11n, s, m)
- **ğŸ¯ TTA (Test Time Augmentation)** - ĞŸĞ¾Ğ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸
- **ğŸ” Smart Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ** - ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¹
- **âš¡ GPU Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ** - CUDA, AMP, Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ±Ğ°Ñ‚Ñ‡Ğ¸
- **ğŸ“Š Comprehensive Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³** - Wandb, TensorBoard, ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸

## ğŸ”§ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

### ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ (config/pipeline_config.json)

```json
{
  "annotation": {
    "confidence_threshold": 0.25,
    "ensemble_models": ["yolo11n", "yolo11s", "yolo11m"],
    "tta_enabled": true
  },
  "training": {
    "epochs": 100,
    "batch_size": 16,
    "learning_rate": 0.01
  }
}
```

## ğŸ¯ API Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

```python
from src.api.detection_api import DetectionAPI

# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
api = DetectionAPI(model_path="path/to/best.pt")

# Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸
results = api.detect_image("image.jpg")

# Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾
results = api.detect_video("video.mp4")

# Batch Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
results = api.detect_batch(["img1.jpg", "img2.jpg"])
```

## ğŸ› ï¸ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

- **Python:** 3.8+
- **GPU:** CUDA 11.0+ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)
- **RAM:** 8GB+
- **GPU Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ:** 4GB+ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)
- **ĞœĞµÑÑ‚Ğ¾ Ğ½Ğ° Ğ´Ğ¸ÑĞºĞµ:** 10GB+

## ğŸ“ Ğ›Ğ¸Ñ†ĞµĞ½Ğ·Ğ¸Ñ

MIT License - ÑĞ¼. [LICENSE](LICENSE) Ñ„Ğ°Ğ¹Ğ».

## ğŸ‘¥ ĞĞ²Ñ‚Ğ¾Ñ€

**Amir** - [@amir2628](https://github.com/amir2628)

---

# English Version

## ğŸ§  Professional Restaurant Object Detection System

**High-performance object detection system using YOLOv11 for restaurant environments**

[![GitHub](https://img.shields.io/badge/GitHub-amir2628-181717?style=flat-square&logo=github)](https://github.com/amir2628/restaurant-object-detection)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-00FFFF?style=flat-square)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

## ğŸ“‹ Project Description

Professional automatic object detection system specifically designed for restaurant environments. The system uses state-of-the-art YOLOv11 architecture and includes a complete machine learning pipeline: from automatic data annotation to production-ready model deployment.

### ğŸ¯ Key Features

- **ğŸ¤– Automatic annotation** using ensemble of models
- **ğŸ¯ High accuracy** - mAP@0.5: 79.7%
- **âš¡ Fast inference** - ~2ms per image
- **ğŸ”§ Production-ready** - ready for deployment
- **ğŸ“Š Comprehensive monitoring** - detailed analytics

### ğŸ½ï¸ Detectable Objects

- ğŸ‘¥ **People** (staff, customers)
- ğŸª‘ **Furniture** (tables, chairs)
- ğŸ½ï¸ **Tableware** (plates, cups, glasses)
- ğŸ´ **Utensils** (forks, knives, spoons)
- ğŸ• **Food** (pizza, cakes, fruits)
- ğŸ“± **Objects** (phones, laptops, books)

## ğŸ—ï¸ Project Architecture

```
restaurant-object-detection/
â”œâ”€â”€ ğŸ“ config/
â”‚   â”œâ”€â”€ pipeline_config.json           # Pipeline configuration
â”‚   â””â”€â”€ model_config.yaml             # Model parameters
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ fix_annotations.py            # ğŸ”§ Fix annotations
â”‚   â”œâ”€â”€ prepare_data.py               # ğŸ“Š Data preparation
â”‚   â”œâ”€â”€ train_model.py                # ğŸš€ Model training
â”‚   â”œâ”€â”€ run_inference.py              # ğŸ¯ Inference
â”‚   â””â”€â”€ generate_final_report.py      # ğŸ“‹ Report generation
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ data/                         # Data processing modules
â”‚   â”œâ”€â”€ models/                       # Models and inference
â”‚   â”œâ”€â”€ utils/                        # Utilities
â”‚   â””â”€â”€ api/                          # API interfaces
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                          # Source videos
â”‚   â”œâ”€â”€ processed/dataset/            # Ready dataset
â”‚   â””â”€â”€ annotations/                  # Annotations
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ experiments/                  # Training results
â”‚   â”œâ”€â”€ inference/                    # Inference results
â”‚   â””â”€â”€ reports/                      # Reports
â””â”€â”€ ğŸ“„ requirements.txt               # Dependencies
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/amir2628/restaurant-object-detection.git
cd restaurant-object-detection

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Source Data

**âš ï¸ IMPORTANT: Place your video files in the correct directory!**

```bash
# Create directory for source videos (if it doesn't exist)
mkdir -p data/raw

# Place your restaurant video files in data/raw/
# Supported formats: .mp4, .avi, .mov, .mkv, .wmv
# Example structure:
# data/raw/
# â”œâ”€â”€ restaurant_video_1.mp4
# â”œâ”€â”€ restaurant_video_2.mp4
# â””â”€â”€ restaurant_video_3.avi
```

### 3. Data Preparation (if annotation needed)

```bash
# Automatic fix for empty annotations
python scripts/fix_annotations.py --dataset "data/processed/dataset"

# Full data preparation pipeline (frame extraction + annotation)
python scripts/prepare_data.py --input "data/raw" --config "config/pipeline_config.json"
```

### 4. Model Training

```bash
# Training with ready dataset
python scripts/train_model.py --data "data/processed/dataset/dataset.yaml"

# Training with custom configuration
python scripts/train_model.py --data "dataset.yaml" --config "config/train_config.json"

# Training with Weights & Biases monitoring
python scripts/train_model.py --data "dataset.yaml" --wandb
```

### 4. Inference

```bash
# Inference on images
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --input-dir "path/to/images"

# Inference on video
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --video "path/to/video.mp4"

# Real-time inference from camera
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --realtime --camera 0
```

### 5. Report Generation

```bash
# Complete project report
python scripts/generate_final_report.py \
  --model-path "outputs/experiments/yolo_*/weights/best.pt" \
  --dataset-dir "data/processed/dataset" \
  --experiment-dir "outputs/experiments/yolo_*" \
  --output "final_report.md" \
  --project-time 8.5
```

## ğŸ“Š Results

### ğŸ† Achieved Metrics

| Metric | Value | Comment |
|--------|-------|---------|
| **mAP@0.5** | **79.7%** | ğŸ¥‡ Excellent result |
| **mAP@0.5:0.95** | **74.2%** | ğŸ¥ˆ High accuracy |
| **Inference Speed** | **~2ms** | âš¡ Real-time processing |
| **Model Size** | **~6MB** | ğŸ“¦ Compact |
| **Training Time** | **17.5 min** | ğŸš€ Fast training |

### ğŸ“ˆ Implementation Features

- **ğŸ¤– Ensemble annotation** - Using 3 models (YOLOv11n, s, m)
- **ğŸ¯ TTA (Test Time Augmentation)** - Improved accuracy
- **ğŸ” Smart filtering** - Automatic removal of low-quality detections
- **âš¡ GPU optimization** - CUDA, AMP, optimized batching
- **ğŸ“Š Comprehensive monitoring** - Wandb, TensorBoard, custom metrics

## ğŸ”§ Configuration

### Main Parameters (config/pipeline_config.json)

```json
{
  "annotation": {
    "confidence_threshold": 0.25,
    "ensemble_models": ["yolo11n", "yolo11s", "yolo11m"],
    "tta_enabled": true
  },
  "training": {
    "epochs": 100,
    "batch_size": 16,
    "learning_rate": 0.01
  }
}
```

## ğŸ¯ API Usage

```python
from src.api.detection_api import DetectionAPI

# Initialization
api = DetectionAPI(model_path="path/to/best.pt")

# Image detection
results = api.detect_image("image.jpg")

# Video detection
results = api.detect_video("video.mp4")

# Batch processing
results = api.detect_batch(["img1.jpg", "img2.jpg"])
```

## ğŸ› ï¸ System Requirements

- **Python:** 3.8+
- **GPU:** CUDA 11.0+ (recommended)
- **RAM:** 8GB+
- **GPU Memory:** 4GB+ (recommended)
- **Disk Space:** 10GB+

## ğŸ“ˆ Performance Benchmarks

- **Real-time processing:** âœ… 30+ FPS
- **Batch processing:** âœ… 500+ images/minute
- **Memory usage:** âœ… <2GB GPU memory
- **Model accuracy:** âœ… Production-ready (79.7% mAP@0.5)

## ğŸš€ Deployment Options

### Docker Deployment
```bash
# Build container
docker build -t restaurant-detector .

# Run inference service
docker run -p 8000:8000 restaurant-detector
```

### API Service
```bash
# Start FastAPI service
python src/api/main.py

# Access at http://localhost:8000/docs
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ‘¥ Author

**Amir** - [@amir2628](https://github.com/amir2628)

## ğŸ™ Acknowledgments

- [Ultralytics](https://github.com/ultralytics/ultralytics) for YOLOv11
- Restaurant industry for inspiration
- Open-source community for tools and libraries

---

<div align="center">

**ğŸŒŸ If this project helped you, please give it a star! ğŸŒŸ**

[![GitHub stars](https://img.shields.io/github/stars/amir2628/restaurant-object-detection?style=social)](https://github.com/amir2628/restaurant-object-detection)
[![GitHub forks](https://img.shields.io/github/forks/amir2628/restaurant-object-detection?style=social)](https://github.com/amir2628/restaurant-object-detection)

</div>