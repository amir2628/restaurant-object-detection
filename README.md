# üçΩÔ∏è Restaurant Object Detection with YOLOv11

> **üìñ README Languages / –Ø–∑—ã–∫–∏ README**  
> This README is available in two languages:  
> ‚Ä¢ [üá∑üá∫ Russian Version](#russian-version) (–†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è)  
> ‚Ä¢ [üá∫üá∏ English Version](#english-version) (English –≤–µ—Ä—Å–∏—è)

---

## üõ†Ô∏è **Technology Stack**

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-27338e?style=for-the-badge&logo=OpenCV&logoColor=white)
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white)
![Ultralytics](https://img.shields.io/badge/YOLOv11-00FFFF?style=for-the-badge&logo=yolo&logoColor=black)

![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge&logo=python&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)

</div>

---

# Russian Version

## üß† –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞—Ö

**–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YOLOv11 –¥–ª—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–Ω–æ–π —Å—Ä–µ–¥—ã**

[![GitHub](https://img.shields.io/badge/GitHub-amir2628-181717?style=flat-square&logo=github)](https://github.com/amir2628/restaurant-object-detection)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-00FFFF?style=flat-square)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

## üìã –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞

–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–ª—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–Ω–æ–π —Å—Ä–µ–¥—ã. –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É YOLOv11 –∏ –≤–∫–ª—é—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: –æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏.

### üéØ –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è** —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
- **üéØ –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - mAP@0.5: 79.7%
- **‚ö° –ë—ã—Å—Ç—Ä—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å** - ~2ms –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- **üîß Production-ready** - –≥–æ—Ç–æ–≤–æ –∫ –≤–Ω–µ–¥—Ä–µ–Ω–∏—é
- **üìä Comprehensive –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –¥–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

### üçΩÔ∏è –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã

- üë• **–õ—é–¥–∏** (–ø–µ—Ä—Å–æ–Ω–∞–ª, –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏)
- ü™ë **–ú–µ–±–µ–ª—å** (—Å—Ç–æ–ª—ã, —Å—Ç—É–ª—å—è)
- üçΩÔ∏è **–ü–æ—Å—É–¥–∞** (—Ç–∞—Ä–µ–ª–∫–∏, —á–∞—à–∫–∏, –±–æ–∫–∞–ª—ã)
- üç¥ **–ü—Ä–∏–±–æ—Ä—ã** (–≤–∏–ª–∫–∏, –Ω–æ–∂–∏, –ª–æ–∂–∫–∏)
- üçï **–ï–¥–∞** (–ø–∏—Ü—Ü–∞, —Ç–æ—Ä—Ç—ã, —Ñ—Ä—É–∫—Ç—ã)
- üì± **–ü—Ä–µ–¥–º–µ—Ç—ã** (—Ç–µ–ª–µ—Ñ–æ–Ω—ã, –Ω–æ—É—Ç–±—É–∫–∏, –∫–Ω–∏–≥–∏)

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
restaurant-object-detection/
‚îú‚îÄ‚îÄ üìÅ config/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_config.json           # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
‚îÇ   ‚îî‚îÄ‚îÄ model_config.yaml             # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ üìÅ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ fix_annotations.py            # üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py               # üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py                # üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ run_inference.py              # üéØ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
‚îÇ   ‚îî‚îÄ‚îÄ generate_final_report.py      # üìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/                         # –ú–æ–¥—É–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ models/                       # –ú–æ–¥–µ–ª–∏ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
‚îÇ   ‚îú‚îÄ‚îÄ utils/                        # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ api/                          # API –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–∏–¥–µ–æ
‚îÇ   ‚îú‚îÄ‚îÄ processed/dataset/            # –ì–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
‚îÇ   ‚îî‚îÄ‚îÄ annotations/                  # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏
‚îú‚îÄ‚îÄ üìÅ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ experiments/                  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ inference/                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
‚îÇ   ‚îî‚îÄ‚îÄ reports/                      # –û—Ç—á–µ—Ç—ã
‚îî‚îÄ‚îÄ üìÑ requirements.txt               # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/amir2628/restaurant-object-detection.git
cd restaurant-object-detection

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt
```

### 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

**‚ö†Ô∏è –í–ê–ñ–ù–û: –ü–æ–º–µ—Å—Ç–∏—Ç–µ –≤–∞—à–∏ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é!**

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –≤–∏–¥–µ–æ (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
mkdir -p data/raw

# –ü–æ–º–µ—Å—Ç–∏—Ç–µ –≤–∞—à–∏ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ –≤ data/raw/
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .mp4, .avi, .mov, .mkv, .wmv
# –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
# data/raw/
# ‚îú‚îÄ‚îÄ restaurant_video_1.mp4
# ‚îú‚îÄ‚îÄ restaurant_video_2.mp4
# ‚îî‚îÄ‚îÄ restaurant_video_3.avi
```

### 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è)

```bash
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
python scripts/fix_annotations.py --dataset "data/processed/dataset"

# –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ + –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è)
python scripts/prepare_data.py --input "data/raw" --config "config/pipeline_config.json"
```

### 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```bash
# –û–±—É—á–µ–Ω–∏–µ —Å –≥–æ—Ç–æ–≤—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º
python scripts/train_model.py --data "data/processed/dataset/dataset.yaml"

# –û–±—É—á–µ–Ω–∏–µ —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
python scripts/train_model.py --data "dataset.yaml" --config "config/train_config.json"

# –û–±—É—á–µ–Ω–∏–µ —Å Weights & Biases –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
python scripts/train_model.py --data "dataset.yaml" --wandb
```

### 4. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å

```bash
# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --input-dir "path/to/images"

# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –≤–∏–¥–µ–æ
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --video "path/to/video.mp4"

# Real-time –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —Å –∫–∞–º–µ—Ä—ã
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --realtime --camera 0
```

### 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤

```bash
# –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç—É
python scripts/generate_final_report.py \
  --model-path "outputs/experiments/yolo_*/weights/best.pt" \
  --dataset-dir "data/processed/dataset" \
  --experiment-dir "outputs/experiments/yolo_*" \
  --output "final_report.md" \
  --project-time 8.5
```

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### üèÜ –î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|---------|----------|-------------|
| **mAP@0.5** | **79.7%** | ü•á –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç |
| **mAP@0.5:0.95** | **74.2%** | ü•à –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |
| **–°–∫–æ—Ä–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞** | **~2ms** | ‚ö° Real-time –æ–±—Ä–∞–±–æ—Ç–∫–∞ |
| **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏** | **~6MB** | üì¶ –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è |
| **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è** | **17.5 –º–∏–Ω** | üöÄ –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ |

### üìà –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

- **ü§ñ Ensemble –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è** - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 3 –º–æ–¥–µ–ª–µ–π (YOLOv11n, s, m)
- **üéØ TTA (Test Time Augmentation)** - –ü–æ–≤—ã—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
- **üîç Smart —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è** - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
- **‚ö° GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** - CUDA, AMP, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∏
- **üìä Comprehensive –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - Wandb, TensorBoard, –∫–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (config/pipeline_config.json)

```json
{
  "annotation": {
    "confidence_threshold": 0.25,
    "ensemble_models": ["yolo11n", "yolo11s", "yolo11m"],
    "tta_enabled": true
  },
  "training": {
    "epochs": 100,
    "batch_size": 16,
    "learning_rate": 0.01
  }
}
```

## üéØ API –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from src.api.detection_api import DetectionAPI

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
api = DetectionAPI(model_path="path/to/best.pt")

# –î–µ—Ç–µ–∫—Ü–∏—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
results = api.detect_image("image.jpg")

# –î–µ—Ç–µ–∫—Ü–∏—è –Ω–∞ –≤–∏–¥–µ–æ
results = api.detect_video("video.mp4")

# Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞
results = api.detect_batch(["img1.jpg", "img2.jpg"])
```

## üõ†Ô∏è –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Python:** 3.8+
- **GPU:** CUDA 11.0+ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- **RAM:** 8GB+
- **GPU –ø–∞–º—è—Ç—å:** 4GB+ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- **–ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ:** 10GB+

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License - —Å–º. [LICENSE](LICENSE) —Ñ–∞–π–ª.

## üë• –ê–≤—Ç–æ—Ä

**Amir** - [@amir2628](https://github.com/amir2628)

---

# English Version

## üß† Professional Restaurant Object Detection System

**High-performance object detection system using YOLOv11 for restaurant environments**

[![GitHub](https://img.shields.io/badge/GitHub-amir2628-181717?style=flat-square&logo=github)](https://github.com/amir2628/restaurant-object-detection)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-00FFFF?style=flat-square)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

## üìã Project Description

Professional automatic object detection system specifically designed for restaurant environments. The system uses state-of-the-art YOLOv11 architecture and includes a complete machine learning pipeline: from automatic data annotation to production-ready model deployment.

### üéØ Key Features

- **ü§ñ Automatic annotation** using ensemble of models
- **üéØ High accuracy** - mAP@0.5: 79.7%
- **‚ö° Fast inference** - ~2ms per image
- **üîß Production-ready** - ready for deployment
- **üìä Comprehensive monitoring** - detailed analytics

### üçΩÔ∏è Detectable Objects

- üë• **People** (staff, customers)
- ü™ë **Furniture** (tables, chairs)
- üçΩÔ∏è **Tableware** (plates, cups, glasses)
- üç¥ **Utensils** (forks, knives, spoons)
- üçï **Food** (pizza, cakes, fruits)
- üì± **Objects** (phones, laptops, books)

## üèóÔ∏è Project Architecture

```
restaurant-object-detection/
‚îú‚îÄ‚îÄ üìÅ config/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_config.json           # Pipeline configuration
‚îÇ   ‚îî‚îÄ‚îÄ model_config.yaml             # Model parameters
‚îú‚îÄ‚îÄ üìÅ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ fix_annotations.py            # üîß Fix annotations
‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py               # üìä Data preparation
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py                # üöÄ Model training
‚îÇ   ‚îú‚îÄ‚îÄ run_inference.py              # üéØ Inference
‚îÇ   ‚îî‚îÄ‚îÄ generate_final_report.py      # üìã Report generation
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/                         # Data processing modules
‚îÇ   ‚îú‚îÄ‚îÄ models/                       # Models and inference
‚îÇ   ‚îú‚îÄ‚îÄ utils/                        # Utilities
‚îÇ   ‚îî‚îÄ‚îÄ api/                          # API interfaces
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Source videos
‚îÇ   ‚îú‚îÄ‚îÄ processed/dataset/            # Ready dataset
‚îÇ   ‚îî‚îÄ‚îÄ annotations/                  # Annotations
‚îú‚îÄ‚îÄ üìÅ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ experiments/                  # Training results
‚îÇ   ‚îú‚îÄ‚îÄ inference/                    # Inference results
‚îÇ   ‚îî‚îÄ‚îÄ reports/                      # Reports
‚îî‚îÄ‚îÄ üìÑ requirements.txt               # Dependencies
```

## üöÄ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/amir2628/restaurant-object-detection.git
cd restaurant-object-detection

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Source Data

**‚ö†Ô∏è IMPORTANT: Place your video files in the correct directory!**

```bash
# Create directory for source videos (if it doesn't exist)
mkdir -p data/raw

# Place your restaurant video files in data/raw/
# Supported formats: .mp4, .avi, .mov, .mkv, .wmv
# Example structure:
# data/raw/
# ‚îú‚îÄ‚îÄ restaurant_video_1.mp4
# ‚îú‚îÄ‚îÄ restaurant_video_2.mp4
# ‚îî‚îÄ‚îÄ restaurant_video_3.avi
```

### 3. Data Preparation (if annotation needed)

```bash
# Automatic fix for empty annotations
python scripts/fix_annotations.py --dataset "data/processed/dataset"

# Full data preparation pipeline (frame extraction + annotation)
python scripts/prepare_data.py --input "data/raw" --config "config/pipeline_config.json"
```

### 4. Model Training

```bash
# Training with ready dataset
python scripts/train_model.py --data "data/processed/dataset/dataset.yaml"

# Training with custom configuration
python scripts/train_model.py --data "dataset.yaml" --config "config/train_config.json"

# Training with Weights & Biases monitoring
python scripts/train_model.py --data "dataset.yaml" --wandb
```

### 4. Inference

```bash
# Inference on images
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --input-dir "path/to/images"

# Inference on video
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --video "path/to/video.mp4"

# Real-time inference from camera
python scripts/run_inference.py \
  --model "outputs/experiments/yolo_*/weights/best.pt" \
  --realtime --camera 0
```

### 5. Report Generation

```bash
# Complete project report
python scripts/generate_final_report.py \
  --model-path "outputs/experiments/yolo_*/weights/best.pt" \
  --dataset-dir "data/processed/dataset" \
  --experiment-dir "outputs/experiments/yolo_*" \
  --output "final_report.md" \
  --project-time 8.5
```

## üìä Results

### üèÜ Achieved Metrics

| Metric | Value | Comment |
|--------|-------|---------|
| **mAP@0.5** | **79.7%** | ü•á Excellent result |
| **mAP@0.5:0.95** | **74.2%** | ü•à High accuracy |
| **Inference Speed** | **~2ms** | ‚ö° Real-time processing |
| **Model Size** | **~6MB** | üì¶ Compact |
| **Training Time** | **17.5 min** | üöÄ Fast training |

### üìà Implementation Features

- **ü§ñ Ensemble annotation** - Using 3 models (YOLOv11n, s, m)
- **üéØ TTA (Test Time Augmentation)** - Improved accuracy
- **üîç Smart filtering** - Automatic removal of low-quality detections
- **‚ö° GPU optimization** - CUDA, AMP, optimized batching
- **üìä Comprehensive monitoring** - Wandb, TensorBoard, custom metrics

## üîß Configuration

### Main Parameters (config/pipeline_config.json)

```json
{
  "annotation": {
    "confidence_threshold": 0.25,
    "ensemble_models": ["yolo11n", "yolo11s", "yolo11m"],
    "tta_enabled": true
  },
  "training": {
    "epochs": 100,
    "batch_size": 16,
    "learning_rate": 0.01
  }
}
```

## üéØ API Usage

```python
from src.api.detection_api import DetectionAPI

# Initialization
api = DetectionAPI(model_path="path/to/best.pt")

# Image detection
results = api.detect_image("image.jpg")

# Video detection
results = api.detect_video("video.mp4")

# Batch processing
results = api.detect_batch(["img1.jpg", "img2.jpg"])
```

## üõ†Ô∏è System Requirements

- **Python:** 3.8+
- **GPU:** CUDA 11.0+ (recommended)
- **RAM:** 8GB+
- **GPU Memory:** 4GB+ (recommended)
- **Disk Space:** 10GB+

## üìà Performance Benchmarks

- **Real-time processing:** ‚úÖ 30+ FPS
- **Batch processing:** ‚úÖ 500+ images/minute
- **Memory usage:** ‚úÖ <2GB GPU memory
- **Model accuracy:** ‚úÖ Production-ready (79.7% mAP@0.5)

## üöÄ Deployment Options

### Docker Deployment
```bash
# Build container
docker build -t restaurant-detector .

# Run inference service
docker run -p 8000:8000 restaurant-detector
```

### API Service
```bash
# Start FastAPI service
python src/api/main.py

# Access at http://localhost:8000/docs
```

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## üìù License

MIT License - see [LICENSE](LICENSE) file.

## üë• Author

**Amir** - [@amir2628](https://github.com/amir2628)

## üôè Acknowledgments

- [Ultralytics](https://github.com/ultralytics/ultralytics) for YOLOv11
- Restaurant industry for inspiration
- Open-source community for tools and libraries

---

<div align="center">

**üåü If this project helped you, please give it a star! üåü**

[![GitHub stars](https://img.shields.io/github/stars/amir2628/restaurant-object-detection?style=social)](https://github.com/amir2628/restaurant-object-detection)
[![GitHub forks](https://img.shields.io/github/forks/amir2628/restaurant-object-detection?style=social)](https://github.com/amir2628/restaurant-object-detection)

</div>