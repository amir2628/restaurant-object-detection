"""
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è YOLOv11
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
"""

import logging
import json
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import torch
from ultralytics import YOLO
import supervision as sv
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import albumentations as A


@dataclass
class DetectionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
    class_id: int
    class_name: str
    confidence: float
    bbox: List[float]  # [x_center, y_center, width, height] –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ
    original_bbox: List[int]  # [x1, y1, x2, y2] –≤ –ø–∏–∫—Å–µ–ª—è—Ö


class SmartAnnotator:
    """
    –£–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
    –∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        self.logger = self._setup_logger()
        self.config = self._load_config(config_path)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        self.models = {}
        self.ensemble_weights = {}
        self._init_models()
        
        # –°–∏—Å—Ç–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        self.validator = AnnotationValidator()
        
        # –¢—Ä–µ–∫–µ—Ä –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats = {
            'total_images': 0,
            'total_detections': 0,
            'filtered_detections': 0,
            'class_distribution': {},
            'confidence_distribution': {},
            'processing_time': 0
        }
    
    def _setup_logger(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞"""
        logger = logging.getLogger(f"{__name__}.SmartAnnotator")
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _load_config(self, config_path: Optional[Path]) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–∞"""
        default_config = {
            'models': {
                'yolo11n': {'weight': 0.3, 'confidence': 0.15},
                'yolo11s': {'weight': 0.4, 'confidence': 0.2},
                'yolo11m': {'weight': 0.3, 'confidence': 0.25}
            },
            'ensemble': {
                'consensus_threshold': 0.6,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ –º–æ–¥–µ–ª–µ–π
                'confidence_boost': 0.1,     # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≥–ª–∞—Å–∏–µ
                'iou_threshold': 0.5
            },
            'filtering': {
                'min_confidence': 0.25,
                'min_area': 200,            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å bbox
                'max_area_ratio': 0.9,      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
                'min_aspect_ratio': 0.1,    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
                'max_aspect_ratio': 10.0,   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
                'edge_threshold': 10        # –û—Ç—Å—Ç—É–ø –æ—Ç –∫—Ä–∞—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            },
            'restaurant_classes': [
                'person', 'chair', 'dining table', 'cup', 'fork', 'knife',
                'spoon', 'bowl', 'bottle', 'wine glass', 'sandwich', 'pizza',
                'cake', 'apple', 'banana', 'orange', 'cell phone', 'laptop', 'book'
            ],
            'augmentation': {
                'enable_tta': True,  # Test Time Augmentation
                'tta_transforms': ['flip', 'rotate', 'scale']
            }
        }
        
        if config_path and config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                default_config.update(user_config)
        
        return default_config
    
    def _init_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π"""
        self.logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π YOLO...")
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        
        for model_name, model_config in self.config['models'].items():
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                model_path = f"{model_name}.pt"
                self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
                
                model = YOLO(model_path)
                model.to(device)
                
                self.models[model_name] = {
                    'model': model,
                    'confidence': model_config['confidence'],
                    'weight': model_config['weight']
                }
                
                self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                
            except Exception as e:
                self.logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {model_name}: {e}")
        
        if not self.models:
            # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é
            self.logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ YOLOv8n...")
            model = YOLO('yolov8n.pt')
            model.to(device)
            self.models['yolov8n'] = {
                'model': model,
                'confidence': 0.2,
                'weight': 1.0
            }
    
    def annotate_dataset(self, 
                        images_dir: Path, 
                        output_dir: Path,
                        batch_size: int = 8,
                        num_workers: int = 4) -> Dict[str, Any]:
        """
        –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
        
        Args:
            images_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        """
        self.logger.info(f"–ù–∞—á–∞–ª–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {images_dir}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        image_files = []
        for ext in image_extensions:
            image_files.extend(list(images_dir.glob(f"*{ext}")))
            image_files.extend(list(images_dir.glob(f"*{ext.upper()}")))
        
        if not image_files:
            self.logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {images_dir}")
            return self.stats
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏")
        self.stats['total_images'] = len(image_files)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏
        processed_count = 0
        failed_count = 0
        
        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞—Ç—á–µ–π
            batches = [image_files[i:i + batch_size] 
                      for i in range(0, len(image_files), batch_size)]
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            future_to_batch = {}
            for batch in batches:
                future = executor.submit(self._process_batch, batch, output_dir)
                future_to_batch[future] = batch
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            with tqdm(total=len(image_files), desc="–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π") as pbar:
                for future in as_completed(future_to_batch):
                    batch = future_to_batch[future]
                    try:
                        batch_results = future.result()
                        processed_count += batch_results['processed']
                        failed_count += batch_results['failed']
                        
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                        for class_name, count in batch_results['class_distribution'].items():
                            self.stats['class_distribution'][class_name] = \
                                self.stats['class_distribution'].get(class_name, 0) + count
                        
                        self.stats['total_detections'] += batch_results['total_detections']
                        self.stats['filtered_detections'] += batch_results['filtered_detections']
                        
                    except Exception as e:
                        self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞: {e}")
                        failed_count += len(batch)
                    
                    pbar.update(len(batch))
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats['processed_images'] = processed_count
        self.stats['failed_images'] = failed_count
        self.stats['success_rate'] = processed_count / len(image_files) if image_files else 0
        
        self.logger.info(f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        self.logger.info(f"  - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}/{len(image_files)}")
        self.logger.info(f"  - –ù–µ—É–¥–∞—á–Ω–æ: {failed_count}")
        self.logger.info(f"  - –í—Å–µ–≥–æ –¥–µ—Ç–µ–∫—Ü–∏–π: {self.stats['total_detections']}")
        self.logger.info(f"  - –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {self.stats['total_detections'] - self.stats['filtered_detections']}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self._save_annotation_stats(output_dir)
        
        return self.stats
    
    def _process_batch(self, image_batch: List[Path], output_dir: Path) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        batch_stats = {
            'processed': 0,
            'failed': 0,
            'total_detections': 0,
            'filtered_detections': 0,
            'class_distribution': {}
        }
        
        for image_path in image_batch:
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                image = cv2.imread(str(image_path))
                if image is None:
                    self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
                    batch_stats['failed'] += 1
                    continue
                
                # –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                detections = self._annotate_single_image(image, image_path)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                annotation_path = output_dir / f"{image_path.stem}.txt"
                self._save_yolo_annotation(detections, annotation_path, image.shape)
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                batch_stats['processed'] += 1
                batch_stats['total_detections'] += len(detections)
                
                for detection in detections:
                    class_name = detection.class_name
                    batch_stats['class_distribution'][class_name] = \
                        batch_stats['class_distribution'].get(class_name, 0) + 1
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {image_path}: {e}")
                batch_stats['failed'] += 1
        
        return batch_stats
    
    def _annotate_single_image(self, image: np.ndarray, image_path: Path) -> List[DetectionResult]:
        """–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–Ω—Å–∞–º–±–ª—è"""
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        all_detections = []
        
        for model_name, model_info in self.models.items():
            try:
                model = model_info['model']
                confidence = model_info['confidence']
                
                # –ë–∞–∑–æ–≤–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è
                results = model(image, conf=confidence, verbose=False)
                model_detections = self._parse_yolo_results(results, model_name)
                
                # Test Time Augmentation (TTA)
                if self.config['augmentation']['enable_tta']:
                    tta_detections = self._apply_tta(image, model, confidence)
                    model_detections.extend(tta_detections)
                
                all_detections.extend(model_detections)
                
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å –º–æ–¥–µ–ª—å—é {model_name}: {e}")
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        consensus_detections = self._apply_ensemble_consensus(all_detections, image.shape)
        filtered_detections = self._filter_detections(consensus_detections, image.shape)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞
        restaurant_detections = self._filter_restaurant_classes(filtered_detections)
        
        return restaurant_detections
    
    def _parse_yolo_results(self, results, model_name: str) -> List[DetectionResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ YOLO"""
        detections = []
        
        if not results or len(results) == 0:
            return detections
        
        result = results[0]  # –ü–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±–∞—Ç—á–µ
        
        if result.boxes is None or len(result.boxes) == 0:
            return detections
        
        boxes = result.boxes.xyxy.cpu().numpy()
        confidences = result.boxes.conf.cpu().numpy()
        class_ids = result.boxes.cls.cpu().numpy().astype(int)
        
        height, width = result.orig_shape
        
        for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):
            if class_id >= len(result.names):
                continue
                
            class_name = result.names[class_id]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç YOLO (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)
            x1, y1, x2, y2 = box
            x_center = (x1 + x2) / 2 / width
            y_center = (y1 + y2) / 2 / height
            w = (x2 - x1) / width
            h = (y2 - y1) / height
            
            detection = DetectionResult(
                class_id=class_id,
                class_name=class_name,
                confidence=float(conf),
                bbox=[x_center, y_center, w, h],
                original_bbox=[int(x1), int(y1), int(x2), int(y2)]
            )
            
            detections.append(detection)
        
        return detections
    
    def _apply_tta(self, image: np.ndarray, model, confidence: float) -> List[DetectionResult]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Test Time Augmentation"""
        tta_detections = []
        
        # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
        if 'flip' in self.config['augmentation']['tta_transforms']:
            flipped = cv2.flip(image, 1)
            results = model(flipped, conf=confidence, verbose=False)
            flipped_detections = self._parse_yolo_results(results, 'tta_flip')
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è –æ—Ç—Ä–∞–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            for det in flipped_detections:
                det.bbox[0] = 1.0 - det.bbox[0]  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º x_center
                det.confidence *= 0.9  # –ù–µ–±–æ–ª—å—à–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è TTA
            
            tta_detections.extend(flipped_detections)
        
        # –ü–æ–≤–æ—Ä–æ—Ç
        if 'rotate' in self.config['augmentation']['tta_transforms']:
            # –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç –Ω–∞ ¬±5 –≥—Ä–∞–¥—É—Å–æ–≤
            for angle in [-5, 5]:
                h, w = image.shape[:2]
                center = (w // 2, h // 2)
                matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                rotated = cv2.warpAffine(image, matrix, (w, h))
                
                results = model(rotated, conf=confidence, verbose=False)
                rotated_detections = self._parse_yolo_results(results, f'tta_rotate_{angle}')
                
                # –°–Ω–∏–∂–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ–≤–µ—Ä–Ω—É—Ç—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                for det in rotated_detections:
                    det.confidence *= 0.85
                
                tta_detections.extend(rotated_detections)
        
        return tta_detections
    
    def _apply_ensemble_consensus(self, all_detections: List[DetectionResult], 
                                image_shape: Tuple[int, int, int]) -> List[DetectionResult]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –∞–Ω—Å–∞–º–±–ª—è"""
        if not all_detections:
            return []
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π –ø–æ IoU
        consensus_detections = []
        used_indices = set()
        
        for i, detection in enumerate(all_detections):
            if i in used_indices:
                continue
            
            # –ü–æ–∏—Å–∫ —Å—Ö–æ–∂–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
            similar_detections = [detection]
            used_indices.add(i)
            
            for j, other_detection in enumerate(all_detections[i+1:], i+1):
                if j in used_indices:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ IoU –∏ –∫–ª–∞—Å—Å–∞
                if (detection.class_name == other_detection.class_name and
                    self._calculate_iou(detection.bbox, other_detection.bbox) > 
                    self.config['ensemble']['iou_threshold']):
                    
                    similar_detections.append(other_detection)
                    used_indices.add(j)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏
            if len(similar_detections) >= 1:  # –ú–∏–Ω–∏–º—É–º –æ–¥–Ω–∞ –¥–µ—Ç–µ–∫—Ü–∏—è
                consensus_det = self._create_consensus_detection(similar_detections)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
                consensus_ratio = len(similar_detections) / len(self.models)
                if consensus_ratio >= self.config['ensemble']['consensus_threshold'] / len(self.models):
                    # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å
                    consensus_det.confidence = min(1.0, 
                        consensus_det.confidence + 
                        self.config['ensemble']['confidence_boost'] * consensus_ratio)
                    
                    consensus_detections.append(consensus_det)
        
        return consensus_detections
    
    def _create_consensus_detection(self, detections: List[DetectionResult]) -> DetectionResult:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏–∑ –≥—Ä—É–ø–ø—ã —Å—Ö–æ–∂–∏—Ö"""
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        total_weight = sum(det.confidence for det in detections)
        
        if total_weight == 0:
            return detections[0]
        
        weighted_bbox = [0, 0, 0, 0]
        for detection in detections:
            weight = detection.confidence / total_weight
            for i in range(4):
                weighted_bbox[i] += detection.bbox[i] * weight
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        max_confidence = max(det.confidence for det in detections)
        
        # –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –∫–ª–∞—Å—Å
        class_votes = {}
        for det in detections:
            key = (det.class_id, det.class_name)
            class_votes[key] = class_votes.get(key, 0) + det.confidence
        
        best_class = max(class_votes.items(), key=lambda x: x[1])[0]
        
        return DetectionResult(
            class_id=best_class[0],
            class_name=best_class[1],
            confidence=max_confidence,
            bbox=weighted_bbox,
            original_bbox=[]  # –ë—É–¥–µ—Ç –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        )
    
    def _calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ IoU –º–µ–∂–¥—É –¥–≤—É–º—è bbox –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ YOLO —Ñ–æ—Ä–º–∞—Ç–∞ –≤ —É–≥–ª—ã
        def yolo_to_corners(bbox):
            x_center, y_center, width, height = bbox
            x1 = x_center - width / 2
            y1 = y_center - height / 2
            x2 = x_center + width / 2
            y2 = y_center + height / 2
            return x1, y1, x2, y2
        
        x1_1, y1_1, x2_1, y2_1 = yolo_to_corners(bbox1)
        x1_2, y1_2, x2_2, y2_2 = yolo_to_corners(bbox2)
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        x1_inter = max(x1_1, x1_2)
        y1_inter = max(y1_1, y1_2)
        x2_inter = min(x2_1, x2_2)
        y2_inter = min(y2_1, y2_2)
        
        if x2_inter <= x1_inter or y2_inter <= y1_inter:
            return 0.0
        
        intersection = (x2_inter - x1_inter) * (y2_inter - y1_inter)
        
        # –ü–ª–æ—â–∞–¥–∏
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _filter_detections(self, detections: List[DetectionResult], 
                          image_shape: Tuple[int, int, int]) -> List[DetectionResult]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ü–∏–π –ø–æ –∫–∞—á–µ—Å—Ç–≤—É"""
        filtered = []
        height, width = image_shape[:2]
        
        for detection in detections:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            if detection.confidence < self.config['filtering']['min_confidence']:
                self.stats['filtered_detections'] += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
            w_pixels = detection.bbox[2] * width
            h_pixels = detection.bbox[3] * height
            area = w_pixels * h_pixels
            
            if area < self.config['filtering']['min_area']:
                self.stats['filtered_detections'] += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            image_area = width * height
            if area / image_area > self.config['filtering']['max_area_ratio']:
                self.stats['filtered_detections'] += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
            aspect_ratio = w_pixels / h_pixels if h_pixels > 0 else float('inf')
            if (aspect_ratio < self.config['filtering']['min_aspect_ratio'] or
                aspect_ratio > self.config['filtering']['max_aspect_ratio']):
                self.stats['filtered_detections'] += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ –∫—Ä–∞—è–º
            edge_threshold = self.config['filtering']['edge_threshold'] / width
            x_center, y_center = detection.bbox[0], detection.bbox[1]
            half_w, half_h = detection.bbox[2] / 2, detection.bbox[3] / 2
            
            if (x_center - half_w < edge_threshold or
                x_center + half_w > 1 - edge_threshold or
                y_center - half_h < edge_threshold or
                y_center + half_h > 1 - edge_threshold):
                # –ù–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é, –Ω–æ —Å–Ω–∏–∂–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                detection.confidence *= 0.8
            
            filtered.append(detection)
        
        return filtered
    
    def _filter_restaurant_classes(self, detections: List[DetectionResult]) -> List[DetectionResult]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º –¥–ª—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ –∫–ª–∞—Å—Å–∞–º"""
        restaurant_classes = set(self.config['restaurant_classes'])
        
        filtered = []
        for detection in detections:
            if detection.class_name in restaurant_classes:
                filtered.append(detection)
            else:
                self.stats['filtered_detections'] += 1
        
        return filtered
    
    def _save_yolo_annotation(self, detections: List[DetectionResult], 
                             output_path: Path, image_shape: Tuple[int, int, int]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO"""
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤
        class_mapping = self._get_class_mapping()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for detection in detections:
                # –ü–æ–ª—É—á–µ–Ω–∏–µ ID –∫–ª–∞—Å—Å–∞ –≤ –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ
                if detection.class_name in class_mapping:
                    class_id = class_mapping[detection.class_name]
                    
                    # –§–æ—Ä–º–∞—Ç YOLO: class_id x_center y_center width height
                    line = f"{class_id} {detection.bbox[0]:.6f} {detection.bbox[1]:.6f} " \
                           f"{detection.bbox[2]:.6f} {detection.bbox[3]:.6f}\n"
                    f.write(line)
    
    def _get_class_mapping(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–Ω–æ–π —Å—Ü–µ–Ω—ã"""
        restaurant_classes = self.config['restaurant_classes']
        return {class_name: idx for idx, class_name in enumerate(restaurant_classes)}
    
    def _save_annotation_stats(self, output_dir: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏"""
        stats_path = output_dir / 'annotation_stats.json'
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤ –∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
        self.stats['class_mapping'] = self._get_class_mapping()
        self.stats['total_classes'] = len(self.config['restaurant_classes'])
        
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {stats_path}")


class AnnotationValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.AnnotationValidator")
    
    def validate_annotation_file(self, annotation_path: Path, 
                                image_path: Optional[Path] = None) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏"""
        validation_result = {
            'valid': True,
            'issues': [],
            'bbox_count': 0,
            'class_distribution': {}
        }
        
        if not annotation_path.exists():
            validation_result['valid'] = False
            validation_result['issues'].append("–§–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return validation_result
        
        try:
            with open(annotation_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            if not lines:
                # –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ (–Ω–µ—Ç –æ–±—ä–µ–∫—Ç–æ–≤)
                return validation_result
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split()
                if len(parts) != 5:
                    validation_result['valid'] = False
                    validation_result['issues'].append(
                        f"–°—Ç—Ä–æ–∫–∞ {line_num}: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–æ–∂–∏–¥–∞–µ—Ç—Å—è 5 –∑–Ω–∞—á–µ–Ω–∏–π)"
                    )
                    continue
                
                try:
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:])
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—Ü
                    if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and
                           0 <= width <= 1 and 0 <= height <= 1):
                        validation_result['valid'] = False
                        validation_result['issues'].append(
                            f"–°—Ç—Ä–æ–∫–∞ {line_num}: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–Ω–µ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –≥—Ä–∞–Ω–∏—Ü [0,1]"
                        )
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
                    if width <= 0 or height <= 0:
                        validation_result['valid'] = False
                        validation_result['issues'].append(
                            f"–°—Ç—Ä–æ–∫–∞ {line_num}: —à–∏—Ä–∏–Ω–∞ –∏–ª–∏ –≤—ã—Å–æ—Ç–∞ <= 0"
                        )
                    
                    validation_result['bbox_count'] += 1
                    validation_result['class_distribution'][class_id] = \
                        validation_result['class_distribution'].get(class_id, 0) + 1
                    
                except ValueError:
                    validation_result['valid'] = False
                    validation_result['issues'].append(
                        f"–°—Ç—Ä–æ–∫–∞ {line_num}: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª"
                    )
            
        except Exception as e:
            validation_result['valid'] = False
            validation_result['issues'].append(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        
        return validation_result


def create_dataset_yaml(dataset_dir: Path, class_mapping: Dict[str, int]):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ dataset.yaml –¥–ª—è YOLO"""
    yaml_content = f"""# –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ
# –°–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏

path: {dataset_dir.absolute()}
train: train/images
val: val/images
test: test/images

# –ö–ª–∞—Å—Å—ã
nc: {len(class_mapping)}
names: {list(class_mapping.keys())}

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
description: "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ"
version: "1.0"
license: "Custom"
"""
    
    yaml_path = dataset_dir / "dataset.yaml"
    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(yaml_content)
    
    return yaml_path


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –¥–ª—è YOLO11")
    parser.add_argument("--images_dir", type=str, required=True, 
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
    parser.add_argument("--output_dir", type=str, required=True,
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
    parser.add_argument("--config", type=str, default=None,
                       help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--batch_size", type=int, default=8,
                       help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞")
    parser.add_argument("--num_workers", type=int, default=4,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤")
    
    args = parser.parse_args()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–∞
    config_path = Path(args.config) if args.config else None
    annotator = SmartAnnotator(config_path)
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    images_dir = Path(args.images_dir)
    output_dir = Path(args.output_dir)
    
    stats = annotator.annotate_dataset(
        images_dir=images_dir,
        output_dir=output_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ dataset.yaml
    class_mapping = annotator._get_class_mapping()
    yaml_path = create_dataset_yaml(output_dir.parent, class_mapping)
    
    print(f"\n‚úÖ –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìÅ –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
    print(f"üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è YOLO: {yaml_path}")
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['processed_images']}")
    print(f"üéØ –í—Å–µ–≥–æ –¥–µ—Ç–µ–∫—Ü–∏–π: {stats['total_detections']}")
    print(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats['success_rate']:.1%}")


if __name__ == "__main__":
    main()