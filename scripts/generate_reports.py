"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤:
- –û—Ç—á–µ—Ç—ã –æ –¥–∞–Ω–Ω—ã—Ö –∏ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–µ
- –û—Ç—á–µ—Ç—ã –æ–± –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏
- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
- –û—Ç—á–µ—Ç—ã –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""
import argparse
import sys
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from datetime import datetime
import yaml

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent))

from src.utils.logger import setup_logging, get_logger
from src.utils.visualization import ReportGenerator, MetricsVisualizer
from src.models.model_manager import ModelManager
from src.data.annotator import AnnotationValidator
from config.config import config

class ComprehensiveReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤"""
    
    def __init__(self, output_dir: Path):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤
        
        Args:
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤
        """
        self.logger = get_logger(__name__)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.report_generator = ReportGenerator()
        self.metrics_visualizer = MetricsVisualizer()
        self.model_manager = ModelManager()
        self.annotation_validator = AnnotationValidator()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        self.logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
    
    def generate_data_quality_report(self, 
                                   dataset_dir: Path,
                                   annotations_dir: Optional[Path] = None) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            dataset_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
            annotations_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ (–µ—Å–ª–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è)
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        self.logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'dataset_directory': str(dataset_dir),
            'analysis_results': {}
        }
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset_structure = self._analyze_dataset_structure(dataset_dir)
        report_data['analysis_results']['dataset_structure'] = dataset_structure
        
        # –ê–Ω–∞–ª–∏–∑ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
        if annotations_dir or (dataset_dir / 'train' / 'labels').exists():
            ann_dir = annotations_dir or dataset_dir / 'train' / 'labels'
            validation_report = self.annotation_validator.validate_annotation_directory(
                ann_dir, dataset_dir / 'train' / 'images'
            )
            report_data['analysis_results']['annotation_quality'] = validation_report
        
        # –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        images_analysis = self._analyze_images_quality(dataset_dir)
        report_data['analysis_results']['images_analysis'] = images_analysis
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞
        html_report = self._create_data_quality_html_report(report_data)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = self.output_dir / 'data_quality_report.html'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö
        json_path = self.output_dir / 'data_quality_report.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"–û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω: {report_path}")
        return report_path
    
    def _analyze_dataset_structure(self, dataset_dir: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        structure = {
            'splits': {},
            'total_images': 0,
            'class_distribution': {},
            'issues': []
        }
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ split'–∞
        for split in ['train', 'val', 'test']:
            split_dir = dataset_dir / split
            if split_dir.exists():
                images_dir = split_dir / 'images'
                labels_dir = split_dir / 'labels'
                
                # –ü–æ–¥—Å—á–µ—Ç —Ñ–∞–π–ª–æ–≤
                image_count = 0
                label_count = 0
                
                if images_dir.exists():
                    for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                        image_count += len(list(images_dir.glob(f"*{ext}")))
                
                if labels_dir.exists():
                    label_count = len(list(labels_dir.glob("*.txt")))
                
                structure['splits'][split] = {
                    'images': image_count,
                    'labels': label_count,
                    'has_mismatch': image_count != label_count
                }
                
                structure['total_images'] += image_count
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã
                if image_count != label_count:
                    structure['issues'].append(
                        f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ {split}: "
                        f"{image_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {label_count} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"
                    )
        
        return structure
    
    def _analyze_images_quality(self, dataset_dir: Path) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        import cv2
        
        analysis = {
            'total_analyzed': 0,
            'corrupted_images': 0,
            'resolution_stats': {
                'widths': [],
                'heights': [],
                'aspects': []
            },
            'file_size_stats': {
                'sizes_mb': [],
                'average_size_mb': 0
            },
            'format_distribution': {}
        }
        
        # –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –≤—Å–µ—Ö splits
        for split in ['train', 'val', 'test']:
            images_dir = dataset_dir / split / 'images'
            if not images_dir.exists():
                continue
            
            image_files = []
            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                image_files.extend(images_dir.glob(f"*{ext}"))
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            sample_size = min(len(image_files), 100)
            sample_files = np.random.choice(image_files, sample_size, replace=False) if sample_size > 0 else []
            
            for img_path in sample_files:
                try:
                    # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
                    file_size_mb = img_path.stat().st_size / (1024 * 1024)
                    analysis['file_size_stats']['sizes_mb'].append(file_size_mb)
                    
                    # –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
                    ext = img_path.suffix.lower()
                    analysis['format_distribution'][ext] = analysis['format_distribution'].get(ext, 0) + 1
                    
                    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    image = cv2.imread(str(img_path))
                    if image is not None:
                        h, w = image.shape[:2]
                        analysis['resolution_stats']['widths'].append(w)
                        analysis['resolution_stats']['heights'].append(h)
                        analysis['resolution_stats']['aspects'].append(w / h)
                        analysis['total_analyzed'] += 1
                    else:
                        analysis['corrupted_images'] += 1
                        
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}")
                    analysis['corrupted_images'] += 1
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if analysis['file_size_stats']['sizes_mb']:
            analysis['file_size_stats']['average_size_mb'] = np.mean(
                analysis['file_size_stats']['sizes_mb']
            )
        
        return analysis
    
    def _create_data_quality_html_report(self, report_data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
        structure = report_data['analysis_results']['dataset_structure']
        images_analysis = report_data['analysis_results']['images_analysis']
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>–û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; }}
                .section {{ margin-bottom: 30px; }}
                .section h2 {{ color: #2c3e50; border-left: 4px solid #3498db; padding-left: 15px; }}
                .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; }}
                .stat-card {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #3498db; }}
                .stat-number {{ font-size: 2em; font-weight: bold; color: #2c3e50; }}
                .stat-label {{ color: #7f8c8d; margin-top: 5px; }}
                .table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                .table th, .table td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
                .table th {{ background-color: #3498db; color: white; font-weight: bold; }}
                .table tr:nth-child(even) {{ background-color: #f2f2f2; }}
                .issue {{ background-color: #fff3cd; border: 1px solid #ffeaa7; border-radius: 4px; padding: 10px; margin: 5px 0; }}
                .issue.error {{ background-color: #f8d7da; border-color: #f5c6cb; }}
                .good {{ color: #27ae60; font-weight: bold; }}
                .warning {{ color: #f39c12; font-weight: bold; }}
                .error {{ color: #e74c3c; font-weight: bold; }}
                .progress-bar {{ width: 100%; height: 20px; background-color: #ecf0f1; border-radius: 10px; overflow: hidden; }}
                .progress-fill {{ height: 100%; background-color: #3498db; transition: width 0.3s ease; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üìä –û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö</h1>
                    <p>–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {report_data['timestamp']}</p>
                    <p>–î–∞—Ç–∞—Å–µ—Ç: {report_data['dataset_directory']}</p>
                </div>

                <div class="section">
                    <h2>üèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞</h2>
                    <div class="stats-grid">
                        <div class="stat-card">
                            <div class="stat-number">{structure['total_images']}</div>
                            <div class="stat-label">–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{len(structure['splits'])}</div>
                            <div class="stat-label">–†–∞–∑–¥–µ–ª–µ–Ω–∏–π (splits)</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{len(structure['issues'])}</div>
                            <div class="stat-label">–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º</div>
                        </div>
                    </div>
                    
                    <table class="table">
                        <tr><th>–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ</th><th>–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è</th><th>–ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏</th><th>–°—Ç–∞—Ç—É—Å</th></tr>
        """
        
        for split, data in structure['splits'].items():
            status = "‚úÖ OK" if not data['has_mismatch'] else "‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ"
            status_class = "good" if not data['has_mismatch'] else "warning"
            
            html_content += f"""
                        <tr>
                            <td>{split}</td>
                            <td>{data['images']}</td>
                            <td>{data['labels']}</td>
                            <td class="{status_class}">{status}</td>
                        </tr>
            """
        
        html_content += """
                    </table>
                </div>

                <div class="section">
                    <h2>üñºÔ∏è –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</h2>
                    <div class="stats-grid">
        """
        
        if images_analysis['total_analyzed'] > 0:
            avg_width = np.mean(images_analysis['resolution_stats']['widths']) if images_analysis['resolution_stats']['widths'] else 0
            avg_height = np.mean(images_analysis['resolution_stats']['heights']) if images_analysis['resolution_stats']['heights'] else 0
            
            html_content += f"""
                        <div class="stat-card">
                            <div class="stat-number">{images_analysis['total_analyzed']}</div>
                            <div class="stat-label">–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{avg_width:.0f}x{avg_height:.0f}</div>
                            <div class="stat-label">–°—Ä–µ–¥–Ω–µ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{images_analysis['file_size_stats']['average_size_mb']:.2f} MB</div>
                            <div class="stat-label">–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{images_analysis['corrupted_images']}</div>
                            <div class="stat-label">–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤</div>
                        </div>
            """
        
        html_content += """
                    </div>
                </div>
        """
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è—Ö, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        if 'annotation_quality' in report_data['analysis_results']:
            ann_quality = report_data['analysis_results']['annotation_quality']
            validity_rate = (ann_quality['valid_files'] / ann_quality['total_files'] * 100) if ann_quality['total_files'] > 0 else 0
            
            html_content += f"""
                <div class="section">
                    <h2>üìù –ö–∞—á–µ—Å—Ç–≤–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π</h2>
                    <div class="stats-grid">
                        <div class="stat-card">
                            <div class="stat-number">{ann_quality['total_files']}</div>
                            <div class="stat-label">–§–∞–π–ª–æ–≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{validity_rate:.1f}%</div>
                            <div class="stat-label">–í–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π</div>
                        </div>
                        <div class="stat-card">
                            <div class="stat-number">{ann_quality['summary_statistics']['total_objects']}</div>
                            <div class="stat-label">–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤</div>
                        </div>
                    </div>
                    
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: {validity_rate}%"></div>
                    </div>
                    <p style="text-align: center; margin-top: 10px;">–ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π</p>
                </div>
            """
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        html_content += """
                <div class="section">
                    <h2>‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã</h2>
        """
        
        if structure['issues']:
            for issue in structure['issues']:
                html_content += f'<div class="issue">{issue}</div>'
        else:
            html_content += '<div class="issue good">‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ</div>'
        
        html_content += """
                </div>
                
                <div class="section">
                    <h2>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
                    <ul>
        """
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        recommendations = self._generate_data_recommendations(report_data)
        for rec in recommendations:
            html_content += f"<li>{rec}</li>"
        
        html_content += """
                    </ul>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_content
    
    def _generate_data_recommendations(self, report_data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""
        recommendations = []
        
        structure = report_data['analysis_results']['dataset_structure']
        images_analysis = report_data['analysis_results']['images_analysis']
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        if structure['issues']:
            recommendations.append("–ò—Å–ø—Ä–∞–≤—å—Ç–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ–∂–¥—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        
        if structure['total_images'] < 1000:
            recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        if images_analysis['corrupted_images'] > 0:
            recommendations.append(f"–£–¥–∞–ª–∏—Ç–µ –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ {images_analysis['corrupted_images']} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        if images_analysis['resolution_stats']['widths']:
            min_width = min(images_analysis['resolution_stats']['widths'])
            max_width = max(images_analysis['resolution_stats']['widths'])
            if max_width / min_width > 5:
                recommendations.append("–ë–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å –≤ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä–∞–∑–º–µ—Ä–æ–≤")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º
        if 'annotation_quality' in report_data['analysis_results']:
            ann_quality = report_data['analysis_results']['annotation_quality']
            validity_rate = (ann_quality['valid_files'] / ann_quality['total_files']) if ann_quality['total_files'] > 0 else 0
            
            if validity_rate < 0.95:
                recommendations.append("–ù–∏–∑–∫–∞—è –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏ –∏—Å–ø—Ä–∞–≤—å—Ç–µ –æ—à–∏–±–∫–∏ –≤ —Ä–∞–∑–º–µ—Ç–∫–µ")
            
            if ann_quality['missing_images'] > 0:
                recommendations.append(f"–ù–∞–π–¥–µ–Ω–æ {ann_quality['missing_images']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        
        if not recommendations:
            recommendations.append("–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö —Ö–æ—Ä–æ—à–µ–µ. –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
        return recommendations
    
    def generate_training_report(self, experiment_dir: Path) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏
        
        Args:
            experiment_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        self.logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏ –¥–ª—è: {experiment_dir}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ–±—É—á–µ–Ω–∏–∏
        training_results_file = experiment_dir / 'training_results.json'
        if not training_results_file.exists():
            raise FileNotFoundError(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {training_results_file}")
        
        with open(training_results_file, 'r', encoding='utf-8') as f:
            training_data = json.load(f)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤
        report_path = self.report_generator.generate_training_report(training_data, self.output_dir)
        
        self.logger.info(f"–û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ —Å–æ–∑–¥–∞–Ω: {report_path}")
        return report_path
    
    def generate_model_comparison_report(self, model_ids: List[str]) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –º–æ–¥–µ–ª–µ–π
        
        Args:
            model_ids: –°–ø–∏—Å–æ–∫ ID –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        self.logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è {len(model_ids)} –º–æ–¥–µ–ª–µ–π")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –º–æ–¥–µ–ª—è—Ö
        models_data = {}
        for model_id in model_ids:
            try:
                model_info = self.model_manager.get_model_info(model_id)
                models_data[model_id] = model_info
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ {model_id}: {e}")
        
        if not models_data:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –æ–± –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        comparison_results = self.model_manager.compare_models(list(models_data.keys()))
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞
        html_report = self._create_model_comparison_html_report(comparison_results, models_data)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = self.output_dir / 'model_comparison_report.html'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö
        json_path = self.output_dir / 'model_comparison_data.json'
        comparison_data = {
            'models_data': models_data,
            'comparison_results': comparison_results,
            'timestamp': datetime.now().isoformat()
        }
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(comparison_data, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–¥–µ–ª–µ–π —Å–æ–∑–¥–∞–Ω: {report_path}")
        return report_path
    
    def _create_model_comparison_html_report(self, comparison_results: Dict[str, Any], 
                                           models_data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–¥–µ–ª–µ–π</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
                .container {{ max-width: 1400px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; }}
                .section {{ margin-bottom: 30px; }}
                .section h2 {{ color: #2c3e50; border-left: 4px solid #e74c3c; padding-left: 15px; }}
                .models-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
                .model-card {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-top: 4px solid #e74c3c; }}
                .model-name {{ font-size: 1.2em; font-weight: bold; color: #2c3e50; margin-bottom: 10px; }}
                .metric-item {{ display: flex; justify-content: space-between; margin: 5px 0; }}
                .metric-label {{ color: #7f8c8d; }}
                .metric-value {{ font-weight: bold; color: #2c3e50; }}
                .best-metric {{ background-color: #d4edda; padding: 2px 8px; border-radius: 4px; color: #155724; }}
                .comparison-table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                .comparison-table th, .comparison-table td {{ border: 1px solid #ddd; padding: 12px; text-align: center; }}
                .comparison-table th {{ background-color: #e74c3c; color: white; font-weight: bold; }}
                .comparison-table tr:nth-child(even) {{ background-color: #f2f2f2; }}
                .winner {{ background-color: #d4edda; font-weight: bold; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üèÜ –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–¥–µ–ª–µ–π</h1>
                    <p>–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().isoformat()}</p>
                    <p>–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è –º–æ–¥–µ–ª–µ–π: {len(models_data)}</p>
                </div>

                <div class="section">
                    <h2>üìã –û–±–∑–æ—Ä –º–æ–¥–µ–ª–µ–π</h2>
                    <div class="models-grid">
        """
        
        # –ö–∞—Ä—Ç–æ—á–∫–∏ –º–æ–¥–µ–ª–µ–π
        for model_id, model_data in models_data.items():
            metrics = model_data.get('metrics', {})
            
            html_content += f"""
                        <div class="model-card">
                            <div class="model-name">üî¨ {model_data.get('name', model_id)}</div>
                            <div class="metric-item">
                                <span class="metric-label">–†–∞–∑–º–µ—Ä:</span>
                                <span class="metric-value">{model_data.get('size_mb', 0):.1f} MB</span>
                            </div>
                            <div class="metric-item">
                                <span class="metric-label">–°–æ–∑–¥–∞–Ω:</span>
                                <span class="metric-value">{model_data.get('created_at', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')[:10]}</span>
                            </div>
                            <div class="metric-item">
                                <span class="metric-label">mAP@0.5:</span>
                                <span class="metric-value">{metrics.get('map50', 0):.4f}</span>
                            </div>
                            <div class="metric-item">
                                <span class="metric-label">Precision:</span>
                                <span class="metric-value">{metrics.get('precision', 0):.4f}</span>
                            </div>
                            <div class="metric-item">
                                <span class="metric-label">Recall:</span>
                                <span class="metric-value">{metrics.get('recall', 0):.4f}</span>
                            </div>
                        </div>
            """
        
        html_content += """
                    </div>
                </div>

                <div class="section">
                    <h2>üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫</h2>
                    <table class="comparison-table">
                        <tr>
                            <th>–ú–æ–¥–µ–ª—å</th>
                            <th>mAP@0.5</th>
                            <th>mAP@0.5:0.95</th>
                            <th>Precision</th>
                            <th>Recall</th>
                            <th>–†–∞–∑–º–µ—Ä (MB)</th>
                        </tr>
        """
        
        # –ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è
        best_values = {}
        for metric in ['map50', 'map50_95', 'precision', 'recall']:
            best_values[metric] = max(
                models_data[mid].get('metrics', {}).get(metric, 0) 
                for mid in models_data.keys()
            )
        
        # –°—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        for model_id, model_data in models_data.items():
            metrics = model_data.get('metrics', {})
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            map50_class = "winner" if metrics.get('map50', 0) == best_values.get('map50', 0) else ""
            precision_class = "winner" if metrics.get('precision', 0) == best_values.get('precision', 0) else ""
            recall_class = "winner" if metrics.get('recall', 0) == best_values.get('recall', 0) else ""
            
            html_content += f"""
                        <tr>
                            <td>{model_data.get('name', model_id)}</td>
                            <td class="{map50_class}">{metrics.get('map50', 0):.4f}</td>
                            <td>{metrics.get('map50_95', 0):.4f}</td>
                            <td class="{precision_class}">{metrics.get('precision', 0):.4f}</td>
                            <td class="{recall_class}">{metrics.get('recall', 0):.4f}</td>
                            <td>{model_data.get('size_mb', 0):.1f}</td>
                        </tr>
            """
        
        html_content += """
                    </table>
                </div>

                <div class="section">
                    <h2>üèÖ –õ—É—á—à–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º</h2>
        """
        
        # –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if 'best_by_metric' in comparison_results:
            for metric, best_info in comparison_results['best_by_metric'].items():
                model_name = models_data.get(best_info['model_id'], {}).get('name', best_info['model_id'])
                html_content += f"""
                    <div class="metric-item">
                        <span class="metric-label">–õ—É—á—à–∏–π {metric}:</span>
                        <span class="best-metric">{model_name} ({best_info['value']:.4f})</span>
                    </div>
                """
        
        html_content += """
                </div>

                <div class="section">
                    <h2>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
                    <ul>
        """
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self._generate_model_recommendations(comparison_results, models_data)
        for rec in recommendations:
            html_content += f"<li>{rec}</li>"
        
        html_content += """
                    </ul>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_content
    
    def _generate_model_recommendations(self, comparison_results: Dict[str, Any], 
                                      models_data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –º–æ–¥–µ–ª—è–º"""
        recommendations = []
        
        if not models_data:
            return ["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"]
        
        # –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if 'best_by_metric' in comparison_results and 'map50' in comparison_results['best_by_metric']:
            best_model_id = comparison_results['best_by_metric']['map50']['model_id']
            best_model_name = models_data.get(best_model_id, {}).get('name', best_model_id)
            best_map = comparison_results['best_by_metric']['map50']['value']
            
            recommendations.append(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å '{best_model_name}' —Å –ª—É—á—à–∏–º mAP@0.5: {best_map:.4f}")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π
        sizes = [data.get('size_mb', 0) for data in models_data.values()]
        if sizes:
            min_size = min(sizes)
            max_size = max(sizes)
            if max_size / min_size > 3:
                recommendations.append("–ë–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö –º–æ–¥–µ–ª–µ–π. –£—á–∏—Ç—ã–≤–∞–π—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
        if 'summary' in comparison_results:
            for metric, stats in comparison_results['summary'].items():
                if stats.get('std', 0) > 0.1:
                    recommendations.append(f"–í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –º–µ—Ç—Ä–∏–∫–µ {metric}. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É")
        
        return recommendations
    
    def generate_performance_report(self, 
                                  model_path: Path,
                                  test_images_dir: Path,
                                  benchmark_results: Optional[Dict[str, Any]] = None) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
            test_images_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            benchmark_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        self.logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã, –∑–∞–ø—É—Å–∫–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π
        if benchmark_results is None:
            from src.models.inference import benchmark_model
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            test_images = []
            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                test_images.extend(test_images_dir.glob(f"*{ext}"))
            
            if not test_images:
                raise ValueError(f"–¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤: {test_images_dir}")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
            test_images = test_images[:50]
            
            benchmark_results = benchmark_model(model_path, test_images)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞
        html_report = self._create_performance_html_report(model_path, benchmark_results)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = self.output_dir / 'performance_report.html'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö
        json_path = self.output_dir / 'performance_data.json'
        performance_data = {
            'model_path': str(model_path),
            'benchmark_results': benchmark_results,
            'timestamp': datetime.now().isoformat()
        }
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(performance_data, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"–û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω: {report_path}")
        return report_path
    
    def _create_performance_html_report(self, model_path: Path, 
                                      benchmark_results: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        fps = benchmark_results.get('fps', 0)
        avg_time = benchmark_results.get('average_time_per_image', 0)
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>–û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; }}
                .section {{ margin-bottom: 30px; }}
                .section h2 {{ color: #2c3e50; border-left: 4px solid #27ae60; padding-left: 15px; }}
                .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; }}
                .metric-card {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; text-align: center; border-top: 4px solid #27ae60; }}
                .metric-number {{ font-size: 2.5em; font-weight: bold; color: #27ae60; }}
                .metric-label {{ color: #7f8c8d; margin-top: 10px; font-size: 0.9em; }}
                .performance-indicator {{ font-size: 1.2em; margin-top: 10px; }}
                .excellent {{ color: #27ae60; }}
                .good {{ color: #f39c12; }}
                .poor {{ color: #e74c3c; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>‚ö° –û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏</h1>
                    <p>–ú–æ–¥–µ–ª—å: {model_path.name}</p>
                    <p>–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().isoformat()}</p>
                </div>

                <div class="section">
                    <h2>üöÄ –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</h2>
                    <div class="metrics-grid">
                        <div class="metric-card">
                            <div class="metric-number">{fps:.1f}</div>
                            <div class="metric-label">FPS<br>(–∫–∞–¥—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É)</div>
                            <div class="performance-indicator {'excellent' if fps > 30 else 'good' if fps > 15 else 'poor'}">
                                {'–û—Ç–ª–∏—á–Ω–æ' if fps > 30 else '–•–æ—Ä–æ—à–æ' if fps > 15 else '–¢—Ä–µ–±—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏'}
                            </div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{avg_time*1000:.0f}</div>
                            <div class="metric-label">–º—Å<br>(–≤—Ä–µ–º—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)</div>
                            <div class="performance-indicator {'excellent' if avg_time < 0.05 else 'good' if avg_time < 0.1 else 'poor'}">
                                {'–ë—ã—Å—Ç—Ä–æ' if avg_time < 0.05 else '–°—Ä–µ–¥–Ω–µ' if avg_time < 0.1 else '–ú–µ–¥–ª–µ–Ω–Ω–æ'}
                            </div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{benchmark_results.get('total_images', 0)}</div>
                            <div class="metric-label">–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π<br>–ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ</div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{benchmark_results.get('total_detections', 0)}</div>
                            <div class="metric-label">–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ<br>–¥–µ—Ç–µ–∫—Ü–∏–π</div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{benchmark_results.get('average_detections_per_image', 0):.1f}</div>
                            <div class="metric-label">–°—Ä–µ–¥–Ω–µ–µ –¥–µ—Ç–µ–∫—Ü–∏–π<br>–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ</div>
                        </div>
                    </div>
                </div>

                <div class="section">
                    <h2>üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞</h2>
        """
        
        inference_stats = benchmark_results.get('inference_time_stats', {})
        if inference_stats:
            html_content += f"""
                    <div class="metrics-grid">
                        <div class="metric-card">
                            <div class="metric-number">{inference_stats.get('min', 0)*1000:.1f}</div>
                            <div class="metric-label">–º—Å<br>–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è</div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{inference_stats.get('max', 0)*1000:.1f}</div>
                            <div class="metric-label">–º—Å<br>–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è</div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{inference_stats.get('mean', 0)*1000:.1f}</div>
                            <div class="metric-label">–º—Å<br>–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è</div>
                        </div>
                        
                        <div class="metric-card">
                            <div class="metric-number">{inference_stats.get('std', 0)*1000:.1f}</div>
                            <div class="metric-label">–º—Å<br>–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ</div>
                        </div>
                    </div>
            """
        
        html_content += """
                </div>

                <div class="section">
                    <h2>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏</h2>
                    <ul>
        """
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        perf_recommendations = self._generate_performance_recommendations(benchmark_results)
        for rec in perf_recommendations:
            html_content += f"<li>{rec}</li>"
        
        html_content += """
                    </ul>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_content
    
    def _generate_performance_recommendations(self, benchmark_results: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        recommendations = []
        
        fps = benchmark_results.get('fps', 0)
        avg_time = benchmark_results.get('average_time_per_image', 0)
        
        if fps < 15:
            recommendations.append("–ù–∏–∑–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (< 15 FPS). –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU")
        elif fps < 30:
            recommendations.append("–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –î–ª—è real-time –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
        else:
            recommendations.append("–û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å! –ú–æ–¥–µ–ª—å –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è real-time –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        if avg_time > 0.1:
            recommendations.append("–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ > 100–º—Å. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –ª–µ–≥–∫–æ–π –º–æ–¥–µ–ª–∏ (YOLOv8n)")
        
        inference_stats = benchmark_results.get('inference_time_stats', {})
        if inference_stats.get('std', 0) > inference_stats.get('mean', 0) * 0.5:
            recommendations.append("–í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã")
        
        return recommendations
    
    def generate_comprehensive_report(self, 
                                    dataset_dir: Path,
                                    experiment_dirs: List[Path],
                                    model_ids: Optional[List[str]] = None) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ –≤—Å–µ–º—É –ø—Ä–æ–µ–∫—Ç—É
        
        Args:
            dataset_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
            experiment_dirs: –°–ø–∏—Å–æ–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
            model_ids: –°–ø–∏—Å–æ–∫ ID –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        self.logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        comprehensive_dir = self.output_dir / "comprehensive_report"
        comprehensive_dir.mkdir(exist_ok=True)
        
        report_sections = {}
        
        # 1. –û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
        try:
            data_report = self.generate_data_quality_report(dataset_dir)
            report_sections['data_quality'] = data_report
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –æ –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        # 2. –û—Ç—á–µ—Ç—ã –æ–± –æ–±—É—á–µ–Ω–∏–∏
        training_reports = []
        for exp_dir in experiment_dirs:
            try:
                # –í—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—è–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                original_output = self.output_dir
                self.output_dir = comprehensive_dir
                
                training_report = self.generate_training_report(exp_dir)
                training_reports.append(training_report)
                
                self.output_dir = original_output
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {exp_dir}: {e}")
        
        report_sections['training_reports'] = training_reports
        
        # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        if model_ids:
            try:
                original_output = self.output_dir
                self.output_dir = comprehensive_dir
                
                comparison_report = self.generate_model_comparison_report(model_ids)
                report_sections['model_comparison'] = comparison_report
                
                self.output_dir = original_output
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
        
        # 4. –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        index_html = self._create_comprehensive_index(report_sections, comprehensive_dir)
        
        index_path = comprehensive_dir / "index.html"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(index_html)
        
        self.logger.info(f"–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {index_path}")
        return index_path
    
    def _create_comprehensive_index(self, report_sections: Dict[str, Any], 
                                  output_dir: Path) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç –ø—Ä–æ–µ–∫—Ç–∞ YOLOv11</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #e0e0e0; padding-bottom: 20px; }}
                .section {{ margin-bottom: 30px; }}
                .section h2 {{ color: #2c3e50; border-left: 4px solid #9b59b6; padding-left: 15px; }}
                .report-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
                .report-card {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; border-top: 4px solid #9b59b6; }}
                .report-title {{ font-size: 1.2em; font-weight: bold; color: #2c3e50; margin-bottom: 10px; }}
                .report-description {{ color: #7f8c8d; margin-bottom: 15px; }}
                .report-link {{ display: inline-block; background-color: #9b59b6; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; transition: background-color 0.3s; }}
                .report-link:hover {{ background-color: #8e44ad; }}
                .summary-stats {{ background-color: #ecf0f1; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}
                .stat-item {{ display: inline-block; margin: 10px 20px; text-align: center; }}
                .stat-number {{ font-size: 1.5em; font-weight: bold; color: #2c3e50; }}
                .stat-label {{ color: #7f8c8d; font-size: 0.9em; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üìä –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç –ø—Ä–æ–µ–∫—Ç–∞ YOLOv11</h1>
                    <p>–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏</p>
                    <p>–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                </div>

                <div class="summary-stats">
                    <h3>üìà –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞</h3>
                    <div class="stat-item">
                        <div class="stat-number">{len(report_sections.get('training_reports', []))}</div>
                        <div class="stat-label">–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">{'–î–∞' if 'data_quality' in report_sections else '–ù–µ—Ç'}</div>
                        <div class="stat-label">–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">{'–î–∞' if 'model_comparison' in report_sections else '–ù–µ—Ç'}</div>
                        <div class="stat-label">–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π</div>
                    </div>
                </div>

                <div class="section">
                    <h2>üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –æ—Ç—á–µ—Ç—ã</h2>
                    <div class="report-grid">
        """
        
        # –ö–∞—Ä—Ç–æ—á–∫–∞ –æ—Ç—á–µ—Ç–∞ –æ –¥–∞–Ω–Ω—ã—Ö
        if 'data_quality' in report_sections:
            html_content += """
                        <div class="report-card">
                            <div class="report-title">üîç –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö</div>
                            <div class="report-description">
                                –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞, –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π.
                                –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö.
                            </div>
                            <a href="../data_quality_report.html" class="report-link">–û—Ç–∫—Ä—ã—Ç—å –æ—Ç—á–µ—Ç</a>
                        </div>
            """
        
        # –ö–∞—Ä—Ç–æ—á–∫–∏ –æ—Ç—á–µ—Ç–æ–≤ –æ–± –æ–±—É—á–µ–Ω–∏–∏
        for i, training_report in enumerate(report_sections.get('training_reports', [])):
            html_content += f"""
                        <div class="report-card">
                            <div class="report-title">üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ #{i+1}</div>
                            <div class="report-description">
                                –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è, –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞,
                                –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
                            </div>
                            <a href="{Path(training_report).name}" class="report-link">–û—Ç–∫—Ä—ã—Ç—å –æ—Ç—á–µ—Ç</a>
                        </div>
            """
        
        # –ö–∞—Ä—Ç–æ—á–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        if 'model_comparison' in report_sections:
            html_content += """
                        <div class="report-card">
                            <div class="report-title">üèÜ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π</div>
                            <div class="report-description">
                                –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏,
                                —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏.
                            </div>
                            <a href="model_comparison_report.html" class="report-link">–û—Ç–∫—Ä—ã—Ç—å –æ—Ç—á–µ—Ç</a>
                        </div>
            """
        
        html_content += """
                    </div>
                </div>

                <div class="section">
                    <h2>üí° –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞</h2>
                    <ul>
                        <li>–†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π</li>
                        <li>–°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏</li>
                        <li>–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</li>
                        <li>–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏</li>
                        <li>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏</li>
                    </ul>
                </div>

                <div class="section">
                    <h2>üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞</h2>
                    <p>
                        –î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –æ—Ç—á–µ—Ç–∞–º –∏ –∞–Ω–∞–ª–∏–∑—É –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –∫–æ–º–∞–Ω–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.
                        –í—Å–µ –æ—Ç—á–µ—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–∏—Å—Ç–µ–º–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ ML –ø—Ä–æ–µ–∫—Ç–∞.
                    </p>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_content


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞"""
    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ YOLOv11",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
  python scripts/generate_reports.py --data-quality --dataset data/datasets/my_dataset

  # –û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏
  python scripts/generate_reports.py --training-report --experiment outputs/experiments/exp_001

  # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
  python scripts/generate_reports.py --model-comparison --model-ids model_1 model_2 model_3

  # –û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
  python scripts/generate_reports.py --performance --model models/trained/best.pt --test-images data/test/images

  # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç
  python scripts/generate_reports.py --comprehensive --dataset data/datasets/my_dataset --experiments outputs/experiments/exp_*

  # –í—Å–µ –æ—Ç—á–µ—Ç—ã —Å—Ä–∞–∑—É
  python scripts/generate_reports.py --all --dataset data/datasets/my_dataset --experiments outputs/experiments/exp_*
        """
    )
    
    # –¢–∏–ø—ã –æ—Ç—á–µ—Ç–æ–≤
    parser.add_argument(
        '--data-quality',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö'
    )
    
    parser.add_argument(
        '--training-report',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏'
    )
    
    parser.add_argument(
        '--model-comparison',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –º–æ–¥–µ–ª–µ–π'
    )
    
    parser.add_argument(
        '--performance',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏'
    )
    
    parser.add_argument(
        '--comprehensive',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç'
    )
    
    parser.add_argument(
        '--all',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—Ç—á–µ—Ç—ã'
    )
    
    # –ü—É—Ç–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument(
        '--dataset',
        type=str,
        help='–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É'
    )
    
    parser.add_argument(
        '--experiment',
        type=str,
        help='–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞'
    )
    
    parser.add_argument(
        '--experiments',
        nargs='+',
        help='–ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤'
    )
    
    parser.add_argument(
        '--model',
        type=str,
        help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏'
    )
    
    parser.add_argument(
        '--model-ids',
        nargs='+',
        help='ID –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è'
    )
    
    parser.add_argument(
        '--test-images',
        type=str,
        help='–ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default='outputs/reports',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤'
    )
    
    parser.add_argument(
        '--log-level',
        type=str,
        default='INFO',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è'
    )
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    setup_logging(log_level=args.log_level)
    logger = get_logger(__name__)
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤")
    logger.info(f"–ê—Ä–≥—É–º–µ–Ω—Ç—ã: {vars(args)}")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        report_generator = ComprehensiveReportGenerator(args.output_dir)
        
        generated_reports = []
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º
        if args.all or args.data_quality:
            if args.dataset:
                logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö...")
                report_path = report_generator.generate_data_quality_report(Path(args.dataset))
                generated_reports.append(('–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö', report_path))
            else:
                logger.warning("–î–ª—è –æ—Ç—á–µ—Ç–∞ –æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --dataset")
        
        if args.all or args.training_report:
            if args.experiment:
                logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏...")
                report_path = report_generator.generate_training_report(Path(args.experiment))
                generated_reports.append(('–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏', report_path))
            elif args.experiments:
                for exp_path in args.experiments:
                    try:
                        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏ –¥–ª—è {exp_path}...")
                        report_path = report_generator.generate_training_report(Path(exp_path))
                        generated_reports.append(('–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏', report_path))
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –¥–ª—è {exp_path}: {e}")
            else:
                logger.warning("–î–ª—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --experiment –∏–ª–∏ --experiments")
        
        if args.all or args.model_comparison:
            if args.model_ids:
                logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –º–æ–¥–µ–ª–µ–π...")
                report_path = report_generator.generate_model_comparison_report(args.model_ids)
                generated_reports.append(('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π', report_path))
            else:
                logger.warning("–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --model-ids")
        
        if args.all or args.performance:
            if args.model and args.test_images:
                logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
                report_path = report_generator.generate_performance_report(
                    Path(args.model), Path(args.test_images)
                )
                generated_reports.append(('–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', report_path))
            else:
                logger.warning("–î–ª—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --model –∏ --test-images")
        
        if args.comprehensive:
            if args.dataset:
                experiments = []
                if args.experiments:
                    experiments = [Path(p) for p in args.experiments]
                elif args.experiment:
                    experiments = [Path(args.experiment)]
                
                logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
                report_path = report_generator.generate_comprehensive_report(
                    Path(args.dataset), experiments, args.model_ids
                )
                generated_reports.append(('–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç', report_path))
            else:
                logger.warning("–î–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --dataset")
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if generated_reports:
            logger.info("‚úÖ –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–û–í –ó–ê–í–ï–†–®–ï–ù–ê!")
            logger.info(f"–°–æ–∑–¥–∞–Ω–æ –æ—Ç—á–µ—Ç–æ–≤: {len(generated_reports)}")
            
            for report_type, report_path in generated_reports:
                logger.info(f"  üìã {report_type}: {report_path}")
            
            logger.info(f"üìÅ –í—Å–µ –æ—Ç—á–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
        else:
            logger.warning("–ù–∏ –æ–¥–∏–Ω –æ—Ç—á–µ—Ç –Ω–µ –±—ã–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞.")
            parser.print_help()
            sys.exit(1)
        
        sys.exit(0)
        
    except KeyboardInterrupt:
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()