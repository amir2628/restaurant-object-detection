"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GroundingDINO
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –µ–¥—ã –∏ –ø–æ—Å—É–¥—ã
"""

import sys
import argparse
import time
import yaml
import shutil
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
import logging

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent))

from src.utils.logger import setup_logger


def check_dataset_structure(dataset_dir: Path) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ YOLO"""
    logger = setup_logger(__name__)
    
    required_dirs = [
        dataset_dir / "train" / "images",
        dataset_dir / "train" / "labels",
        dataset_dir / "val" / "images", 
        dataset_dir / "val" / "labels",
        dataset_dir / "test" / "images",
        dataset_dir / "test" / "labels"
    ]
    
    missing_dirs = []
    for dir_path in required_dirs:
        if not dir_path.exists():
            missing_dirs.append(str(dir_path))
    
    if missing_dirs:
        logger.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {missing_dirs}")
        return False
    
    logger.info("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
    return True


def create_dataset_structure(dataset_dir: Path):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    logger = setup_logger(__name__)
    
    directories = [
        "train/images", "train/labels",
        "val/images", "val/labels", 
        "test/images", "test/labels"
    ]
    
    for directory in directories:
        dir_path = dataset_dir / directory
        dir_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {dir_path}")
    
    logger.info("üèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞")


def create_dataset_yaml_with_groundingdino_classes(dataset_dir: Path):
    """–°–æ–∑–¥–∞–Ω–∏–µ dataset.yaml —Å –∫–ª–∞—Å—Å–∞–º–∏ GroundingDINO"""
    logger = setup_logger(__name__)
    
    # –ö–ª–∞—Å—Å—ã –¥–ª—è GroundingDINO (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–Ω–æ–π —Å—Ä–µ–¥—ã)
    restaurant_classes = [
        'chicken',     # –ö—É—Ä–∏—Ü–∞
        'meat',        # –ú—è—Å–æ
        'salad',       # –°–∞–ª–∞—Ç
        'soup',        # –°—É–ø
        'cup',         # –ß–∞—à–∫–∞
        'plate',       # –¢–∞—Ä–µ–ª–∫–∞
        'bowl',        # –ú–∏—Å–∫–∞
        'spoon',       # –õ–æ–∂–∫–∞
        'fork',        # –í–∏–ª–∫–∞
        'knife'        # –ù–æ–∂
    ]
    
    yaml_config = {
        'path': str(dataset_dir.absolute()),
        'train': 'train/images',
        'val': 'val/images',
        'test': 'test/images',
        'nc': len(restaurant_classes),
        'names': restaurant_classes
    }
    
    yaml_path = dataset_dir / "dataset.yaml"
    
    try:
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω/–æ–±–Ω–æ–≤–ª–µ–Ω dataset.yaml: {yaml_path}")
        logger.info(f"üìã –ö–ª–∞—Å—Å—ã GroundingDINO ({len(restaurant_classes)}): {', '.join(restaurant_classes)}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è dataset.yaml: {e}")


def auto_annotate_with_groundingdino(image_path: Path, restaurant_classes: List[str], 
                                    confidence_threshold: float = 0.25) -> List[Dict]:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GroundingDINO
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        restaurant_classes: –°–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO
    """
    logger = setup_logger(__name__)
    
    try:
        # –ò–º–ø–æ—Ä—Ç GroundingDINO
        from groundingdino.util.inference import load_model, predict, load_image
        import torch
        import os
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏
        checkpoint_path = "groundingdino_swinb_cogcoor.pth"
        if not os.path.exists(checkpoint_path):
            logger.warning(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ GroundingDINO –Ω–µ –Ω–∞–π–¥–µ–Ω: {checkpoint_path}")
            return []
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–∫–µ—à–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        if not hasattr(auto_annotate_with_groundingdino, 'model'):
            # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            config_paths = [
                "GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py",
                "groundingdino_config.py"
            ]
            
            model = None
            for config_path in config_paths:
                if os.path.exists(config_path):
                    try:
                        model = load_model(config_path, checkpoint_path)
                        logger.info(f"‚úÖ GroundingDINO –∑–∞–≥—Ä—É–∂–µ–Ω —Å –∫–æ–Ω—Ñ–∏–≥–æ–º: {config_path}")
                        break
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å –∫–æ–Ω—Ñ–∏–≥–æ–º {config_path}: {e}")
                        continue
            
            if model is None:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                try:
                    model = load_model(checkpoint_path)
                    logger.info("‚úÖ GroundingDINO –∑–∞–≥—Ä—É–∂–µ–Ω –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                except Exception as e:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å GroundingDINO: {e}")
                    return []
            
            auto_annotate_with_groundingdino.model = model
        
        model = auto_annotate_with_groundingdino.model
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        prompt = " . ".join(restaurant_classes) + " ."
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_source, image = load_image(str(image_path))
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
        boxes, logits, phrases = predict(
            model=model,
            image=image,
            caption=prompt,
            box_threshold=confidence_threshold,
            text_threshold=confidence_threshold,
            device=device
        )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        detections = []
        
        if len(boxes) > 0:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–µ–Ω–∑–æ—Ä–æ–≤
            if hasattr(boxes, 'cpu'):
                boxes = boxes.cpu().numpy()
            if hasattr(logits, 'cpu'):
                logits = logits.cpu().numpy()
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            from PIL import Image
            img = Image.open(image_path)
            img_width, img_height = img.size
            img.close()
            
            for i, (box, confidence, phrase) in enumerate(zip(boxes, logits, phrases)):
                # –ú–∞–ø–ø–∏–Ω–≥ —Ñ—Ä–∞–∑—ã –Ω–∞ –∫–ª–∞—Å—Å
                phrase_lower = str(phrase).lower().strip()
                mapped_class = None
                
                for class_name in restaurant_classes:
                    if class_name.lower() in phrase_lower:
                        mapped_class = class_name
                        break
                
                if mapped_class and confidence >= confidence_threshold:
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ ID –∫–ª–∞—Å—Å–∞
                    class_id = restaurant_classes.index(mapped_class)
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (GroundingDINO –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)
                    x_center, y_center, width, height = box[:4]
                    
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                    if (0 <= x_center <= 1 and 0 <= y_center <= 1 and
                        0 < width <= 1 and 0 < height <= 1):
                        
                        detection = {
                            'class_name': mapped_class,
                            'class_id': class_id,
                            'confidence': float(confidence),
                            'bbox': [x_center, y_center, width, height]
                        }
                        detections.append(detection)
        
        return detections
        
    except ImportError:
        logger.error("‚ùå GroundingDINO –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install groundingdino-py")
        return []
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {e}")
        return []


def remove_duplicate_detections(detections: List[Dict], iou_threshold: float = 0.6) -> List[Dict]:
    """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –¥–µ—Ç–µ–∫—Ü–∏–π"""
    if len(detections) <= 1:
        return detections
    
    # –ü—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ IoU
    filtered_detections = []
    
    for i, detection in enumerate(detections):
        is_duplicate = False
        
        for j, other_detection in enumerate(filtered_detections):
            # –†–∞—Å—á–µ—Ç IoU –º–µ–∂–¥—É –±–æ–∫—Å–∞–º–∏
            box1 = detection['bbox']
            box2 = other_detection['bbox']
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ —Ü–µ–Ω—Ç—Ä + —Ä–∞–∑–º–µ—Ä –≤ —É–≥–ª—ã
            def center_to_corners(bbox):
                x_center, y_center, width, height = bbox
                x1 = x_center - width / 2
                y1 = y_center - height / 2
                x2 = x_center + width / 2
                y2 = y_center + height / 2
                return [x1, y1, x2, y2]
            
            corners1 = center_to_corners(box1)
            corners2 = center_to_corners(box2)
            
            # –†–∞—Å—á–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
            x1 = max(corners1[0], corners2[0])
            y1 = max(corners1[1], corners2[1])
            x2 = min(corners1[2], corners2[2])
            y2 = min(corners1[3], corners2[3])
            
            if x2 > x1 and y2 > y1:
                intersection = (x2 - x1) * (y2 - y1)
                area1 = box1[2] * box1[3]
                area2 = box2[2] * box2[3]
                union = area1 + area2 - intersection
                
                iou = intersection / union if union > 0 else 0
                
                if iou > iou_threshold:
                    # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é —Å –±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                    if detection['confidence'] <= other_detection['confidence']:
                        is_duplicate = True
                        break
                    else:
                        # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –¥–µ—Ç–µ–∫—Ü–∏—é –Ω–æ–≤–æ–π
                        filtered_detections[j] = detection
                        is_duplicate = True
                        break
        
        if not is_duplicate:
            filtered_detections.append(detection)
    
    return filtered_detections


class AnnotationFixer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å GroundingDINO"""
    
    def __init__(self, dataset_dir: Path, config: Dict[str, Any] = None):
        self.dataset_dir = Path(dataset_dir)
        self.config = config or self._get_default_config()
        self.logger = setup_logger(self.__class__.__name__)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'start_time': time.time(),
            'total_processed': 0,
            'total_annotated': 0,
            'total_errors': 0,
            'splits_processed': []
        }
    
    def _get_default_config(self) -> Dict[str, Any]:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å –∫–ª–∞—Å—Å–∞–º–∏ GroundingDINO"""
        return {
            'restaurant_classes': [
                'chicken', 'meat', 'salad', 'soup', 'cup',
                'plate', 'bowl', 'spoon', 'fork', 'knife'
            ],
            'auto_annotation': {
                'enabled': True,
                'confidence_threshold': 0.25,
                'method': 'groundingdino',
                'checkpoint_path': 'groundingdino_swinb_cogcoor.pth'
            },
            'processing': {
                'create_structure_if_missing': True,
                'overwrite_existing': False,
                'splits_to_process': ['train', 'val', 'test']
            }
        }
    
    def run_fix_process(self):
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"""
        self.logger.info("üîß –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å GroundingDINO")
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if not check_dataset_structure(self.dataset_dir):
                if self.config['processing']['create_structure_if_missing']:
                    create_dataset_structure(self.dataset_dir)
                else:
                    raise ValueError("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
            
            # 2. –°–æ–∑–¥–∞–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ dataset.yaml
            create_dataset_yaml_with_groundingdino_classes(self.dataset_dir)
            
            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ split
            for split in self.config['processing']['splits_to_process']:
                self._process_split(split)
            
            # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            self._generate_report()
            
            self.logger.info("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {e}")
            raise
    
    def _process_split(self, split: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ split (train/val/test)"""
        self.logger.info(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ {split} –Ω–∞–±–æ—Ä–∞...")
        
        images_dir = self.dataset_dir / split / "images"
        labels_dir = self.dataset_dir / split / "labels"
        
        if not images_dir.exists():
            self.logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {images_dir}")
            return
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(images_dir.glob(f"*{ext}"))
            image_files.extend(images_dir.glob(f"*{ext.upper()}"))
        
        if not image_files:
            self.logger.warning(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {images_dir}")
            return
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {split}")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        processed_count = 0
        annotated_count = 0
        
        for image_path in image_files:
            try:
                annotation_path = labels_dir / f"{image_path.stem}.txt"
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                needs_annotation = (
                    not annotation_path.exists() or
                    annotation_path.stat().st_size == 0 or
                    self.config['processing']['overwrite_existing']
                )
                
                if needs_annotation and self.config['auto_annotation']['enabled']:
                    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è —Å GroundingDINO
                    detections = auto_annotate_with_groundingdino(
                        image_path,
                        self.config['restaurant_classes'],
                        self.config['auto_annotation']['confidence_threshold']
                    )
                    
                    # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                    detections = remove_duplicate_detections(detections)
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                    self._save_yolo_annotation(detections, annotation_path)
                    
                    if detections:
                        annotated_count += 1
                        self.logger.debug(f"‚úÖ –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(detections)} –æ–±—ä–µ–∫—Ç–æ–≤ –≤ {image_path.name}")
                    else:
                        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                        annotation_path.touch()
                        self.logger.debug(f"üìù –°–æ–∑–¥–∞–Ω–∞ –ø—É—Å—Ç–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –¥–ª—è {image_path.name}")
                
                elif not annotation_path.exists():
                    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –∞–≤—Ç–æ–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞
                    annotation_path.touch()
                    self.logger.debug(f"üìù –°–æ–∑–¥–∞–Ω–∞ –ø—É—Å—Ç–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –¥–ª—è {image_path.name}")
                
                processed_count += 1
                
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {image_path}: {e}")
                self.stats['total_errors'] += 1
                continue
        
        self.stats['total_processed'] += processed_count
        self.stats['total_annotated'] += annotated_count
        self.stats['splits_processed'].append(split)
        
        self.logger.info(f"‚úÖ {split}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}, –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–æ {annotated_count}")
    
    def _save_yolo_annotation(self, detections: List[Dict], annotation_path: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO"""
        try:
            with open(annotation_path, 'w', encoding='utf-8') as f:
                for detection in detections:
                    bbox = detection['bbox']
                    class_id = detection['class_id']
                    
                    # –§–æ—Ä–º–∞—Ç YOLO: class_id x_center y_center width height
                    line = f"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n"
                    f.write(line)
                    
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ {annotation_path}: {e}")
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            annotation_path.touch()
    
    def _generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ä–∞–±–æ—Ç–µ"""
        total_time = time.time() - self.stats['start_time']
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'method': 'GroundingDINO',
            'execution_time_seconds': round(total_time, 2),
            'statistics': {
                'total_processed': self.stats['total_processed'],
                'total_annotated': self.stats['total_annotated'],
                'total_errors': self.stats['total_errors'],
                'splits_processed': self.stats['splits_processed']
            },
            'configuration': {
                'classes_used': self.config['restaurant_classes'],
                'confidence_threshold': self.config['auto_annotation']['confidence_threshold'],
                'auto_annotation_enabled': self.config['auto_annotation']['enabled']
            },
            'dataset_structure': {
                'dataset_directory': str(self.dataset_dir),
                'yaml_config': str(self.dataset_dir / "dataset.yaml")
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_path = self.dataset_dir / "annotation_fix_report.json"
        
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"üìã –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        self.logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        self.logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {self.stats['total_processed']}, "
                        f"–∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–æ {self.stats['total_annotated']}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GroundingDINO",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

1. –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (—Å–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π):
   python scripts/fix_annotations.py --dataset "data/processed/dataset"

2. –° –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π GroundingDINO:
   python scripts/fix_annotations.py --dataset "data/processed/dataset" --auto-annotate

3. –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π:
   python scripts/fix_annotations.py --dataset "data/processed/dataset" --create-structure --auto-annotate

4. –¢–æ–ª—å–∫–æ –¥–ª—è train split:
   python scripts/fix_annotations.py --dataset "data/processed/dataset" --splits train

5. –° –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:
   python scripts/fix_annotations.py --dataset "data/processed/dataset" --auto-annotate --confidence 0.3

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–≤—Ç–æ–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏:
- –§–∞–π–ª groundingdino_swinb_cogcoor.pth –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
- –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π groundingdino-py: pip install groundingdino-py

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç:
- –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ YOLO
- –°–æ–∑–¥–∞–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å GroundingDINO
- –°–æ–∑–¥–∞–µ—Ç dataset.yaml —Å –∫–ª–∞—Å—Å–∞–º–∏ –µ–¥—ã –∏ –ø–æ—Å—É–¥—ã
- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã

–ö–ª–∞—Å—Å—ã –¥–ª—è GroundingDINO:
chicken, meat, salad, soup, cup, plate, bowl, spoon, fork, knife
        """
    )
    
    parser.add_argument(
        '--dataset',
        type=str,
        required=True,
        help='–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞'
    )
    
    parser.add_argument(
        '--auto-annotate',
        action='store_true',
        help='–í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é —Å –ø–æ–º–æ—â—å—é GroundingDINO'
    )
    
    parser.add_argument(
        '--create-structure',
        action='store_true',
        help='–°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ –µ—Å–ª–∏ –æ–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'
    )
    
    parser.add_argument(
        '--confidence',
        type=float,
        default=0.25,
        help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è GroundingDINO (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.25)'
    )
    
    parser.add_argument(
        '--splits',
        nargs='+',
        default=['train', 'val', 'test'],
        help='–°–ø–∏—Å–æ–∫ splits –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: train val test)'
    )
    
    parser.add_argument(
        '--overwrite',
        action='store_true',
        help='–ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏'
    )
    
    args = parser.parse_args()
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ GroundingDINO –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è
        if args.auto_annotate:
            groundingdino_path = Path("groundingdino_swinb_cogcoor.pth")
            if not groundingdino_path.exists():
                print("\n‚ùå –û–®–ò–ë–ö–ê: –î–ª—è –∞–≤—Ç–æ–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ GroundingDINO!")
                print(f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª: {groundingdino_path.absolute()}")
                print("\n–°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å:")
                print("wget https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swinb_cogcoor.pth")
                sys.exit(1)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config = {
            'restaurant_classes': [
                'chicken', 'meat', 'salad', 'soup', 'cup',
                'plate', 'bowl', 'spoon', 'fork', 'knife'
            ],
            'auto_annotation': {
                'enabled': args.auto_annotate,
                'confidence_threshold': args.confidence,
                'method': 'groundingdino',
                'checkpoint_path': 'groundingdino_swinb_cogcoor.pth'
            },
            'processing': {
                'create_structure_if_missing': args.create_structure,
                'overwrite_existing': args.overwrite,
                'splits_to_process': args.splits
            }
        }
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ —Ñ–∏–∫—Å–µ—Ä–∞
        fixer = AnnotationFixer(
            dataset_dir=Path(args.dataset),
            config=config
        )
        
        fixer.run_fix_process()
        
        print("\n" + "="*60)
        print("üéâ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ê–ù–ù–û–¢–ê–¶–ò–ô –° GROUNDINGDINO –ó–ê–í–ï–†–®–ï–ù–û!")
        print("="*60)
        print(f"üìÅ –î–∞—Ç–∞—Å–µ—Ç: {args.dataset}")
        print(f"üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {args.dataset}/dataset.yaml")
        print(f"üìã –û—Ç—á–µ—Ç: {args.dataset}/annotation_fix_report.json")
        
        if args.auto_annotate:
            print(f"üß† –ú–µ—Ç–æ–¥ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: GroundingDINO")
            print(f"üéØ –ö–ª–∞—Å—Å—ã: chicken, meat, salad, soup, cup, plate, bowl, spoon, fork, knife")
            print(f"üìä –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {args.confidence}")
        else:
            print("üìù –°–æ–∑–¥–∞–Ω—ã –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        
        print(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ splits: {', '.join(args.splits)}")
        print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∑–∞–ø—É—Å—Ç–∏—Ç–µ train_model.py")
        print("="*60)
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        print("\nüí° –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
        print("- –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª groundingdino_swinb_cogcoor.pth")
        print("- –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω groundingdino-py")
        print("- –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
        print("- –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º")
        sys.exit(1)


if __name__ == "__main__":
    main()