"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è YOLO11 —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –ø—É—Å—Ç—ã–º–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
"""

import sys
import logging
import argparse
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
import time
import json
import torch
import numpy as np
from ultralytics import YOLO
try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False
    print("‚ö†Ô∏è Wandb –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Wandb –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω–æ.")

try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    PLOTTING_AVAILABLE = True
except ImportError:
    PLOTTING_AVAILABLE = False
    print("‚ö†Ô∏è Matplotlib/Seaborn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –±—É–¥—É—Ç –æ—Ç–∫–ª—é—á–µ–Ω—ã.")

def setup_logger(name: str) -> logging.Logger:
    """–ü—Ä–æ—Å—Ç–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞"""
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger

class SimpleDeviceManager:
    """–ü—Ä–æ—Å—Ç–æ–π –º–µ–Ω–µ–¥–∂–µ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤"""
    @staticmethod
    def get_optimal_device():
        if torch.cuda.is_available():
            return f"cuda:{torch.cuda.current_device()}"
        return "cpu"

class SimpleMetrics:
    """–ü—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å –¥–ª—è –º–µ—Ç—Ä–∏–∫"""
    def __init__(self):
        pass


class ProfessionalYOLOTrainer:
    """
    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è YOLO11 —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        self.logger = setup_logger(self.__class__.__name__)
        self.config = self._load_config(config_path)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.device_manager = SimpleDeviceManager()
        self.metrics = SimpleMetrics()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
        self.training_state = {
            'start_time': None,
            'end_time': None,
            'best_map50': 0.0,
            'best_map50_95': 0.0,
            'epochs_completed': 0,
            'early_stopping_counter': 0,
            'training_interrupted': False
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ wandb –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        self.use_wandb = (WANDB_AVAILABLE and 
                         self.config.get('logging', {}).get('wandb', {}).get('enabled', False))
        if self.use_wandb:
            self._init_wandb()
    
    def _load_config(self, config_path: Optional[Path] = None) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        default_config = {
            'model': {
                'size': 'n',  # n, s, m, l, x
                'input_size': 640,
                'pretrained': True,
                'freeze_backbone': False,
                'freeze_epochs': 0
            },
            'training': {
                'epochs': 100,
                'batch_size': 16,
                'learning_rate': 0.01,
                'patience': 15,
                'min_lr': 1e-6,
                'optimizer': 'AdamW',
                'weight_decay': 0.0005,
                'momentum': 0.937,
                'scheduler': 'cosine',
                'warmup_epochs': 3,
                'warmup_momentum': 0.8,
                'warmup_bias_lr': 0.1,
                'save_period': 10,
                'val_period': 1
            },
            'augmentation': {
                'mosaic': 1.0,
                'mixup': 0.0,
                'copy_paste': 0.0,
                'degrees': 0.0,
                'translate': 0.1,
                'scale': 0.5,
                'shear': 0.0,
                'perspective': 0.0,
                'hsv_h': 0.015,
                'hsv_s': 0.7,
                'hsv_v': 0.4,
                'flipud': 0.0,
                'fliplr': 0.5
            },
            'validation': {
                'conf_threshold': 0.001,
                'iou_threshold': 0.6,
                'max_det': 300,
                'save_json': True,
                'save_hybrid': False,
                'plots': True
            },
            'optimization': {
                'amp': True,  # Automatic Mixed Precision
                'single_cls': False,
                'rect': False,
                'cos_lr': False,
                'close_mosaic': 10,
                'resume': False,
                'overlap_mask': True,
                'mask_ratio': 4
            },
            'callbacks': {
                'early_stopping': True,
                'model_checkpoint': True,
                'lr_scheduler': True,
                'tensorboard': True
            },
            'logging': {
                'verbose': True,
                'save_dir': 'outputs/experiments',
                'name': 'yolo_restaurant_detection',
                'exist_ok': True,
                'wandb': {
                    'enabled': False,
                    'project': 'restaurant-object-detection',
                    'entity': None,
                    'tags': ['yolo11', 'restaurant', 'detection']
                }
            }
        }
        
        if config_path and config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                if config_path.suffix.lower() in ['.yaml', '.yml']:
                    user_config = yaml.safe_load(f)
                else:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
        
        return default_config
    
    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """–ì–ª—É–±–æ–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è"""
        for key, value in update_dict.items():
            if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value
    
    def _init_wandb(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Weights & Biases"""
        if not WANDB_AVAILABLE:
            self.logger.warning("‚ö†Ô∏è Wandb –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –æ—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ")
            self.use_wandb = False
            return
            
        try:
            wandb_config = self.config['logging']['wandb']
            wandb.init(
                project=wandb_config['project'],
                entity=wandb_config.get('entity'),
                tags=wandb_config.get('tags', []),
                config=self.config,
                name=f"{self.config['logging']['name']}_{int(time.time())}"
            )
            self.logger.info("‚úÖ Weights & Biases –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å wandb: {e}")
            self.use_wandb = False
    
    def train_model(self, dataset_yaml: Path, resume_from: Optional[Path] = None) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            dataset_yaml: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
            resume_from: –ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        self.training_state['start_time'] = time.time()
        self.logger.info("üöÄ –ù–∞—á–∞–ª–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è YOLO11")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
            self._validate_dataset(dataset_yaml)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
            model = self._initialize_model(resume_from)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
            train_params = self._prepare_training_params(dataset_yaml)
            
            # –ü—Ä–µ–¥–æ–±—É—á–∞—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            self._pre_training_checks(model, dataset_yaml)
            
            # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
            results = self._run_training(model, train_params)
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._post_training_analysis(model, results)
            
            return results
            
        except KeyboardInterrupt:
            self.logger.warning("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            self.training_state['training_interrupted'] = True
            return {}
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            raise
        finally:
            self.training_state['end_time'] = time.time()
            self._log_training_summary()
    
    def _validate_dataset(self, dataset_yaml: Path):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º"""
        self.logger.info("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        if not dataset_yaml.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_yaml}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
        with open(dataset_yaml, 'r', encoding='utf-8') as f:
            dataset_config = yaml.safe_load(f)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = ['path', 'train', 'val', 'nc', 'names']
        for field in required_fields:
            if field not in dataset_config:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –≤ dataset.yaml: {field}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–µ–π
        dataset_path = Path(dataset_config['path'])
        if not dataset_path.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {dataset_path}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
        splits_info = {}
        for split in ['train', 'val']:
            if split in dataset_config:
                split_path = dataset_path / dataset_config[split]
                if split_path.is_dir():
                    # –ï—Å–ª–∏ –ø—É—Ç—å —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é images
                    images_dir = split_path
                    labels_dir = split_path.parent / 'labels'
                else:
                    # –ï—Å–ª–∏ –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π
                    images_dir = dataset_path / split / 'images'
                    labels_dir = dataset_path / split / 'labels'
                
                if not images_dir.exists():
                    raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {images_dir}")
                
                if not labels_dir.exists():
                    self.logger.warning(f"‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {labels_dir}")
                    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è labels
                    labels_dir.mkdir(parents=True, exist_ok=True)
                
                # –ü–æ–¥—Å—á–µ—Ç —Ñ–∞–π–ª–æ–≤
                image_files = []
                for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                    image_files.extend(list(images_dir.glob(f"*{ext}")))
                    image_files.extend(list(images_dir.glob(f"*{ext.upper()}")))
                
                label_files = list(labels_dir.glob("*.txt"))
                
                # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
                if len(label_files) == 0 and len(image_files) > 0:
                    self.logger.warning(f"‚ö†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è {split}")
                    for image_file in image_files:
                        label_file = labels_dir / f"{image_file.stem}.txt"
                        if not label_file.exists():
                            label_file.touch()  # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
                    label_files = list(labels_dir.glob("*.txt"))
                
                splits_info[split] = {
                    'images': len(image_files),
                    'labels': len(label_files),
                    'images_dir': str(images_dir),
                    'labels_dir': str(labels_dir)
                }
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        self.logger.info(f"üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
        self.logger.info(f"  - –ö–ª–∞—Å—Å—ã: {dataset_config['nc']} ({', '.join(dataset_config['names'])})")
        for split, info in splits_info.items():
            self.logger.info(f"  - {split.upper()}: {info['images']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {info['labels']} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
        if splits_info.get('train', {}).get('images', 0) == 0:
            raise ValueError("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        
        if splits_info.get('val', {}).get('images', 0) == 0:
            self.logger.warning("‚ö†Ô∏è –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏!")
        
        self.logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–æ–π–¥–µ–Ω–∞")
    
    def _initialize_model(self, resume_from: Optional[Path] = None) -> YOLO:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ YOLO"""
        self.logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ YOLO11...")
        
        model_config = self.config['model']
        
        if resume_from and resume_from.exists():
            self.logger.info(f"üîÑ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å: {resume_from}")
            model = YOLO(str(resume_from))
        else:
            if model_config['pretrained']:
                model_name = f"yolo11{model_config['size']}.pt"
                self.logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {model_name}")
                model = YOLO(model_name)
            else:
                model_name = f"yolo11{model_config['size']}.yaml"
                self.logger.info(f"üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –Ω—É–ª—è: {model_name}")
                model = YOLO(model_name)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        device = self.device_manager.get_optimal_device()
        model.to(device)
        
        self.logger.info(f"üíª –ú–æ–¥–µ–ª—å —Ä–∞–∑–º–µ—â–µ–Ω–∞ –Ω–∞: {device}")
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        total_params = sum(p.numel() for p in model.model.parameters())
        trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)
        
        self.logger.info(f"üìà –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        self.logger.info(f"  - –í—Å–µ–≥–æ: {total_params:,}")
        self.logger.info(f"  - –û–±—É—á–∞–µ–º—ã–µ: {trainable_params:,}")
        
        return model
    
    def _prepare_training_params(self, dataset_yaml: Path) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("‚öôÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        save_dir = Path(self.config['logging']['save_dir'])
        experiment_name = f"{self.config['logging']['name']}_{int(time.time())}"
        experiment_dir = save_dir / experiment_name
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        train_params = {
            'data': str(dataset_yaml),
            'epochs': self.config['training']['epochs'],
            'batch': self.config['training']['batch_size'],
            'imgsz': self.config['model']['input_size'],
            'lr0': self.config['training']['learning_rate'],
            'lrf': self.config['training']['min_lr'] / self.config['training']['learning_rate'],
            'momentum': self.config['training']['momentum'],
            'weight_decay': self.config['training']['weight_decay'],
            'warmup_epochs': self.config['training']['warmup_epochs'],
            'warmup_momentum': self.config['training']['warmup_momentum'],
            'warmup_bias_lr': self.config['training']['warmup_bias_lr'],
            'optimizer': self.config['training']['optimizer'],
            'patience': self.config['training']['patience'],
            'save_period': self.config['training']['save_period'],
            'val': self.config['training']['val_period'] == 1,
            'project': str(save_dir),
            'name': experiment_name,
            'exist_ok': self.config['logging']['exist_ok'],
            'verbose': self.config['logging']['verbose']
        }
        
        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        augmentation = self.config['augmentation']
        train_params.update({
            'mosaic': augmentation['mosaic'],
            'mixup': augmentation['mixup'],
            'copy_paste': augmentation['copy_paste'],
            'degrees': augmentation['degrees'],
            'translate': augmentation['translate'],
            'scale': augmentation['scale'],
            'shear': augmentation['shear'],
            'perspective': augmentation['perspective'],
            'hsv_h': augmentation['hsv_h'],
            'hsv_s': augmentation['hsv_s'],
            'hsv_v': augmentation['hsv_v'],
            'flipud': augmentation['flipud'],
            'fliplr': augmentation['fliplr']
        })
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = self.config['validation']
        train_params.update({
            'conf': validation['conf_threshold'],
            'iou': validation['iou_threshold'],
            'max_det': validation['max_det'],
            'save_json': validation['save_json'],
            'plots': validation['plots']
        })
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        optimization = self.config['optimization']
        train_params.update({
            'amp': optimization['amp'],
            'single_cls': optimization['single_cls'],
            'rect': optimization['rect'],
            'cos_lr': optimization['cos_lr'],
            'close_mosaic': optimization['close_mosaic'],
            'resume': optimization['resume'],
            'overlap_mask': optimization['overlap_mask'],
            'mask_ratio': optimization['mask_ratio']
        })
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_path = experiment_dir / 'training_config.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_path}")
        self.logger.info(f"üìÅ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {experiment_dir}")
        
        return train_params
    
    def _pre_training_checks(self, model: YOLO, dataset_yaml: Path):
        """–ü—Ä–µ–¥–æ–±—É—á–∞—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        self.logger.info("üîß –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ GPU
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            self.logger.info(f"üéÆ GPU –ø–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
            
            if gpu_memory < 4:
                self.logger.warning("‚ö†Ô∏è –ú–∞–ª–æ GPU –ø–∞–º—è—Ç–∏, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å batch_size")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ batch_size
        recommended_batch = self._estimate_optimal_batch_size()
        current_batch = self.config['training']['batch_size']
        
        if current_batch > recommended_batch:
            self.logger.warning(f"‚ö†Ô∏è –ë–æ–ª—å—à–æ–π batch_size: {current_batch}, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: {recommended_batch}")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π forward pass
        try:
            test_input = torch.randn(1, 3, self.config['model']['input_size'], self.config['model']['input_size'])
            if torch.cuda.is_available():
                test_input = test_input.cuda()
            
            with torch.no_grad():
                _ = model.model(test_input)
            
            self.logger.info("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π forward pass —É—Å–ø–µ—à–µ–Ω")
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º forward pass: {e}")
            raise
    
    def _estimate_optimal_batch_size(self) -> int:
        """–û—Ü–µ–Ω–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞"""
        if not torch.cuda.is_available():
            return 4
        
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        input_size = self.config['model']['input_size']
        
        # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º—É–ª–∞
        if input_size <= 640:
            if gpu_memory_gb >= 12:
                return 32
            elif gpu_memory_gb >= 8:
                return 16
            elif gpu_memory_gb >= 6:
                return 8
            else:
                return 4
        else:
            return max(2, int(gpu_memory_gb / 2))
    
    def _run_training(self, model: YOLO, train_params: Dict[str, Any]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
        
        # Callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        def on_train_epoch_end(trainer):
            self.training_state['epochs_completed'] = trainer.epoch + 1
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ wandb
            if self.use_wandb and hasattr(trainer, 'metrics'):
                wandb.log({
                    'epoch': trainer.epoch,
                    'train/box_loss': trainer.loss.item() if hasattr(trainer, 'loss') else 0,
                    'lr': trainer.optimizer.param_groups[0]['lr'] if hasattr(trainer, 'optimizer') else 0
                })
        
        def on_val_end(trainer):
            if hasattr(trainer, 'metrics') and trainer.metrics:
                metrics = trainer.metrics
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–µ—Ç—Ä–∏–∫
                if hasattr(metrics, 'box') and hasattr(metrics.box, 'map50'):
                    current_map50 = metrics.box.map50
                    if current_map50 > self.training_state['best_map50']:
                        self.training_state['best_map50'] = current_map50
                        self.logger.info(f"üéØ –ù–æ–≤—ã–π –ª—É—á—à–∏–π mAP@0.5: {current_map50:.4f}")
                
                if hasattr(metrics, 'box') and hasattr(metrics.box, 'map'):
                    current_map50_95 = metrics.box.map
                    if current_map50_95 > self.training_state['best_map50_95']:
                        self.training_state['best_map50_95'] = current_map50_95
                        self.logger.info(f"üéØ –ù–æ–≤—ã–π –ª—É—á—à–∏–π mAP@0.5:0.95: {current_map50_95:.4f}")
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ wandb
                if self.use_wandb:
                    wandb_metrics = {
                        'val/mAP50': getattr(metrics.box, 'map50', 0),
                        'val/mAP50-95': getattr(metrics.box, 'map', 0),
                        'val/precision': getattr(metrics.box, 'mp', 0),
                        'val/recall': getattr(metrics.box, 'mr', 0)
                    }
                    wandb.log(wandb_metrics)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ callback'–æ–≤
        if hasattr(model, 'add_callback'):
            model.add_callback('on_train_epoch_end', on_train_epoch_end)
            model.add_callback('on_val_end', on_val_end)
        
        try:
            # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
            results = model.train(**train_params)
            
            self.logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            raise
    
    def _post_training_analysis(self, model: YOLO, results):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è...")
        
        try:
            # –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
            if hasattr(results, 'save_dir'):
                results_dir = Path(results.save_dir)
            else:
                results_dir = Path(self.config['logging']['save_dir']) / self.config['logging']['name']
            
            # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
            self._analyze_training_metrics(results_dir)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            self._create_custom_visualizations(results_dir)
            
            # –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏
            self._analyze_model_performance(model, results_dir)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            self._create_training_report(results_dir)
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –ø–æ—Å—Ç–∞–Ω–∞–ª–∏–∑–µ: {e}")
    
    def _analyze_training_metrics(self, results_dir: Path):
        """–ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üìà –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è...")
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        results_csv = results_dir / 'results.csv'
        if not results_csv.exists():
            self.logger.warning("‚ö†Ô∏è –§–∞–π–ª results.csv –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        try:
            import pandas as pd
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç—Ä–∏–∫
            df = pd.read_csv(results_csv)
            df.columns = df.columns.str.strip()  # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if 'train/box_loss' in df.columns:
                final_train_loss = df['train/box_loss'].iloc[-1]
                self.logger.info(f"üìâ –§–∏–Ω–∞–ª—å–Ω–∞—è train loss: {final_train_loss:.4f}")
            
            if 'val/box_loss' in df.columns:
                final_val_loss = df['val/box_loss'].iloc[-1]
                self.logger.info(f"üìâ –§–∏–Ω–∞–ª—å–Ω–∞—è val loss: {final_val_loss:.4f}")
            
            # –õ—É—á—à–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            if 'metrics/mAP50(B)' in df.columns:
                best_map50 = df['metrics/mAP50(B)'].max()
                self.logger.info(f"üéØ –õ—É—á—à–∏–π mAP@0.5: {best_map50:.4f}")
            
            if 'metrics/mAP50-95(B)' in df.columns:
                best_map50_95 = df['metrics/mAP50-95(B)'].max()
                self.logger.info(f"üéØ –õ—É—á—à–∏–π mAP@0.5:0.95: {best_map50_95:.4f}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫: {e}")
    
    def _create_custom_visualizations(self, results_dir: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"""
        if not PLOTTING_AVAILABLE:
            self.logger.warning("‚ö†Ô∏è Matplotlib –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return
            
        self.logger.info("üé® –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
            plt.style.use('default')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Å—Ç–∏–ª—å
            
            # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è
            self._plot_training_curves(results_dir)
            
            # –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–æ–≤
            self._plot_class_distribution(results_dir)
            
            # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
            self._plot_loss_analysis(results_dir)
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π: {e}")
    
    def _plot_training_curves(self, results_dir: Path):
        """–ì—Ä–∞—Ñ–∏–∫ –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        if not PLOTTING_AVAILABLE:
            return
            
        results_csv = results_dir / 'results.csv'
        if not results_csv.exists():
            return
        
        try:
            import pandas as pd
            
            df = pd.read_csv(results_csv)
            df.columns = df.columns.str.strip()
            
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è YOLO11', fontsize=16, fontweight='bold')
            
            # mAP –≥—Ä–∞—Ñ–∏–∫–∏
            if 'metrics/mAP50(B)' in df.columns:
                axes[0, 0].plot(df.index, df['metrics/mAP50(B)'], label='mAP@0.5', linewidth=2)
                axes[0, 0].set_title('mAP@0.5')
                axes[0, 0].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[0, 0].set_ylabel('mAP')
                axes[0, 0].grid(True, alpha=0.3)
                axes[0, 0].legend()
            
            if 'metrics/mAP50-95(B)' in df.columns:
                axes[0, 1].plot(df.index, df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', linewidth=2, color='orange')
                axes[0, 1].set_title('mAP@0.5:0.95')
                axes[0, 1].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[0, 1].set_ylabel('mAP')
                axes[0, 1].grid(True, alpha=0.3)
                axes[0, 1].legend()
            
            # Loss –≥—Ä–∞—Ñ–∏–∫–∏
            if 'train/box_loss' in df.columns:
                axes[1, 0].plot(df.index, df['train/box_loss'], label='Train Box Loss', linewidth=2, color='red')
                if 'val/box_loss' in df.columns:
                    axes[1, 0].plot(df.index, df['val/box_loss'], label='Val Box Loss', linewidth=2, color='blue')
                axes[1, 0].set_title('Box Loss')
                axes[1, 0].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[1, 0].set_ylabel('Loss')
                axes[1, 0].grid(True, alpha=0.3)
                axes[1, 0].legend()
            
            # Learning Rate
            if 'lr/pg0' in df.columns:
                axes[1, 1].plot(df.index, df['lr/pg0'], label='Learning Rate', linewidth=2, color='green')
                axes[1, 1].set_title('Learning Rate')
                axes[1, 1].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[1, 1].set_ylabel('LR')
                axes[1, 1].grid(True, alpha=0.3)
                axes[1, 1].legend()
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            output_path = results_dir / 'training_curves_custom.png'
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def _plot_class_distribution(self, results_dir: Path):
        """–ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤"""
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–∞—Ö –∏–∑ confusion matrix
            confusion_matrix_path = results_dir / 'confusion_matrix.png'
            if confusion_matrix_path.exists():
                self.logger.info("üìä Confusion matrix —É–∂–µ —Å–æ–∑–¥–∞–Ω–∞ YOLO")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–ª–∞—Å—Å–æ–≤: {e}")
    
    def _plot_loss_analysis(self, results_dir: Path):
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ—Ä—å"""
        if not PLOTTING_AVAILABLE:
            return
            
        results_csv = results_dir / 'results.csv'
        if not results_csv.exists():
            return
        
        try:
            import pandas as pd
            
            df = pd.read_csv(results_csv)
            df.columns = df.columns.str.strip()
            
            # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö loss –∫–æ–ª–æ–Ω–æ–∫
            loss_columns = [col for col in df.columns if 'loss' in col.lower()]
            
            if not loss_columns:
                return
            
            fig, ax = plt.subplots(figsize=(12, 8))
            
            # –ü—Ä–æ—Å—Ç—ã–µ —Ü–≤–µ—Ç–∞ –≤–º–µ—Å—Ç–æ seaborn
            colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
            
            for i, col in enumerate(loss_columns):
                color = colors[i % len(colors)]
                ax.plot(df.index, df[col], label=col, linewidth=2, color=color)
            
            ax.set_title('–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø–æ—Ç–µ—Ä—å', fontsize=14, fontweight='bold')
            ax.set_xlabel('–≠–ø–æ—Ö–∞')
            ax.set_ylabel('Loss')
            ax.grid(True, alpha=0.3)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            output_path = results_dir / 'loss_analysis.png'
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ç–µ—Ä—å: {e}")
    
    def _analyze_model_performance(self, model: YOLO, results_dir: Path):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        self.logger.info("‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...")
        
        try:
            # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if hasattr(model, 'model'):
                total_params = sum(p.numel() for p in model.model.parameters())
                trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)
                
                performance_info = {
                    'total_parameters': total_params,
                    'trainable_parameters': trainable_params,
                    'model_size_mb': total_params * 4 / (1024 * 1024),  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ
                    'training_time_minutes': (self.training_state.get('end_time', time.time()) - 
                                            self.training_state.get('start_time', 0)) / 60,
                    'epochs_completed': self.training_state.get('epochs_completed', 0),
                    'best_map50': self.training_state.get('best_map50', 0),
                    'best_map50_95': self.training_state.get('best_map50_95', 0)
                }
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                perf_path = results_dir / 'performance_analysis.json'
                with open(perf_path, 'w', encoding='utf-8') as f:
                    json.dump(performance_info, f, ensure_ascii=False, indent=2)
                
                self.logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {perf_path}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
    
    def _create_training_report(self, results_dir: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        self.logger.info("üìã –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏...")
        
        try:
            report = {
                'training_summary': {
                    'start_time': time.strftime('%Y-%m-%d %H:%M:%S', 
                                               time.localtime(self.training_state.get('start_time', 0))),
                    'end_time': time.strftime('%Y-%m-%d %H:%M:%S', 
                                             time.localtime(self.training_state.get('end_time', 0))),
                    'total_duration_minutes': (self.training_state.get('end_time', time.time()) - 
                                             self.training_state.get('start_time', 0)) / 60,
                    'epochs_completed': self.training_state.get('epochs_completed', 0),
                    'training_interrupted': self.training_state.get('training_interrupted', False)
                },
                'best_metrics': {
                    'best_map50': self.training_state.get('best_map50', 0),
                    'best_map50_95': self.training_state.get('best_map50_95', 0)
                },
                'configuration': self.config,
                'files_generated': {
                    'best_weights': str(results_dir / 'weights' / 'best.pt'),
                    'last_weights': str(results_dir / 'weights' / 'last.pt'),
                    'results_csv': str(results_dir / 'results.csv'),
                    'training_curves': str(results_dir / 'results.png')
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report_path = results_dir / 'training_report.json'
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"üìã –û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
    
    def _log_training_summary(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        total_time = (self.training_state.get('end_time', time.time()) - 
                     self.training_state.get('start_time', 0)) / 60
        
        self.logger.info("\n" + "="*60)
        self.logger.info("üìã –ò–¢–û–ì–ò –û–ë–£–ß–ï–ù–ò–Ø YOLO11")
        self.logger.info("="*60)
        self.logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {total_time:.1f} –º–∏–Ω—É—Ç")
        self.logger.info(f"üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–æ —ç–ø–æ—Ö: {self.training_state.get('epochs_completed', 0)}")
        self.logger.info(f"üéØ –õ—É—á—à–∏–π mAP@0.5: {self.training_state.get('best_map50', 0):.4f}")
        self.logger.info(f"üéØ –õ—É—á—à–∏–π mAP@0.5:0.95: {self.training_state.get('best_map50_95', 0):.4f}")
        
        if self.training_state.get('training_interrupted'):
            self.logger.warning("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –ø—Ä–µ—Ä–≤–∞–Ω–æ")
        else:
            self.logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        self.logger.info("="*60)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ YOLO11 –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    # –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    python scripts/train_model.py --data data/datasets/restaurant_detection/dataset.yaml
    
    # –û–±—É—á–µ–Ω–∏–µ —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    python scripts/train_model.py --data dataset.yaml --config config/train_config.json
    
    # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
    python scripts/train_model.py --data dataset.yaml --resume runs/train/exp/weights/last.pt
    
    # –û–±—É—á–µ–Ω–∏–µ —Å Weights & Biases
    python scripts/train_model.py --data dataset.yaml --wandb
        """
    )
    
    parser.add_argument(
        "--data",
        type=str,
        required=True,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É dataset.yaml"
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"
    )
    
    parser.add_argument(
        "--resume",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è"
    )
    
    parser.add_argument(
        "--wandb",
        action="store_true",
        help="–í–∫–ª—é—á–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Weights & Biases"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"
    )
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—É—Ç–µ–π
        dataset_yaml = Path(args.data)
        config_path = Path(args.config) if args.config else None
        resume_from = Path(args.resume) if args.resume else None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
        trainer = ProfessionalYOLOTrainer(config_path)
        
        # –í–∫–ª—é—á–µ–Ω–∏–µ wandb –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        if args.wandb and WANDB_AVAILABLE:
            trainer.config['logging']['wandb']['enabled'] = True
            trainer.use_wandb = True
            trainer._init_wandb()
        elif args.wandb and not WANDB_AVAILABLE:
            print("‚ö†Ô∏è Wandb –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –Ω–æ –±—ã–ª –∑–∞–ø—Ä–æ—à–µ–Ω. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º: pip install wandb")
        
        # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
        results = trainer.train_model(dataset_yaml, resume_from)
        
        if results:
            print("\nüéâ –û–±—É—á–µ–Ω–∏–µ YOLO11 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            print(f"üéØ –õ—É—á—à–∏–π mAP@0.5: {trainer.training_state.get('best_map50', 0):.4f}")
            print(f"üéØ –õ—É—á—à–∏–π mAP@0.5:0.95: {trainer.training_state.get('best_map50_95', 0):.4f}")
            print("\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ outputs/experiments/")
            print("üöÄ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å inference:")
            print("   python scripts/run_inference.py --weights runs/train/exp/weights/best.pt")
            sys.exit(0)
        else:
            print("\n‚ùå –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()