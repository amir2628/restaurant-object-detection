"""
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ YOLO11 –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä GPU/CPU –∏ –ø–æ–ª–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞
"""

import sys
import argparse
import logging
import json
import time
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import setup_logger

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    from ultralytics import YOLO
    import torch
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    print("‚ùå Ultralytics –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ultralytics")
    sys.exit(1)

try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

class DeviceManager:
    """–ü—Ä–æ—Å—Ç–æ–π –º–µ–Ω–µ–¥–∂–µ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ GPU/CPU"""
    
    def __init__(self, preferred_device: str = "auto"):
        self.logger = setup_logger(__name__)
        self.preferred_device = preferred_device
        self.device = self._select_device()
        
    def _select_device(self):
        """–í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        if self.preferred_device.lower() == "cpu":
            return "cpu"
        elif self.preferred_device.lower() == "cuda" or self.preferred_device.lower() == "gpu":
            if torch.cuda.is_available():
                return 0  # CUDA device 0
            else:
                self.logger.warning("‚ö†Ô∏è CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ CPU")
                return "cpu"
        else:  # auto
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                
                self.logger.info(f"üéÆ –ù–∞–π–¥–µ–Ω–æ GPU: {gpu_name}")
                self.logger.info(f"üéÆ GPU –ø–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
                self.logger.info(f"üéÆ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {gpu_count}")
                
                return 0  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é GPU
            else:
                self.logger.info("üíª GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                return "cpu"
    
    def get_device(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"""
        return self.device
    
    def get_recommended_batch_size(self, base_batch_size: int = 16) -> int:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        if self.device == "cpu":
            return max(base_batch_size // 4, 1)
        
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            
            if gpu_memory >= 24:  # High-end GPU
                return base_batch_size * 2
            elif gpu_memory >= 12:  # Mid-range GPU  
                return base_batch_size
            elif gpu_memory >= 8:  # Entry-level GPU
                return max(base_batch_size // 2, 4)
            elif gpu_memory >= 4:  # Low memory GPU
                return max(base_batch_size // 4, 2)
            else:  # Very low memory
                return 1
        
        return base_batch_size

class ProfessionalYOLOTrainer:
    """–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä YOLO11 —Å –ø–æ–ª–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
    
    def __init__(self, config_path: Optional[Path] = None, device: str = "auto"):
        self.logger = setup_logger(self.__class__.__name__)
        self.config = self._load_config(config_path)
        self.device_manager = DeviceManager(device)
        self.model = None
        self.experiment_name = None
        self.experiment_dir = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        self.training_stats = {
            'start_time': None,
            'end_time': None,
            'epochs_completed': 0,
            'best_metrics': {},
            'training_interrupted': False
        }
    
    def _load_config(self, config_path: Optional[Path] = None) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        default_config = {
            'model': {
                'size': 'n',  # n, s, m, l, x
                'input_size': 640,
                'pretrained': True
            },
            'training': {
                'epochs': 100,
                'batch_size': 16,
                'learning_rate': 0.01,
                'weight_decay': 0.0005,
                'momentum': 0.937,
                'warmup_epochs': 3,
                'warmup_momentum': 0.8,
                'warmup_bias_lr': 0.1,
                'optimizer': 'AdamW',
                'patience': 50,
                'save_period': 10,
                'val_period': 1,
                'amp': True,  # Automatic Mixed Precision
                'workers': 8
            },
            'augmentation': {
                'mosaic': 1.0,
                'mixup': 0.0,
                'copy_paste': 0.0,
                'degrees': 0.0,
                'translate': 0.1,
                'scale': 0.5,
                'shear': 0.0,
                'perspective': 0.0,
                'hsv_h': 0.015,
                'hsv_s': 0.7,
                'hsv_v': 0.4,
                'flipud': 0.0,
                'fliplr': 0.5
            },
            'validation': {
                'conf_threshold': 0.001,
                'iou_threshold': 0.6,
                'max_det': 300,
                'save_json': False,
                'plots': True
            },
            'logging': {
                'verbose': True,
                'exist_ok': True,
                'wandb': {
                    'enabled': False,
                    'project': 'restaurant-object-detection',
                    'name': None
                }
            }
        }
        
        if config_path and config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                
                # –°–ª–∏—è–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
                def merge_configs(base, update):
                    for key, value in update.items():
                        if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                            merge_configs(base[key], value)
                        else:
                            base[key] = value
                
                merge_configs(default_config, user_config)
                self.logger.info(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ {config_path}")
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
                self.logger.info("üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        
        return default_config
    
    def validate_dataset(self, dataset_yaml: Path) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        self.logger.info("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        if not dataset_yaml.exists():
            raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {dataset_yaml}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
        with open(dataset_yaml, 'r', encoding='utf-8') as f:
            dataset_config = yaml.safe_load(f)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = ['path', 'train', 'val', 'nc', 'names']
        for field in required_fields:
            if field not in dataset_config:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –≤ dataset.yaml: {field}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–µ–π
        dataset_path = Path(dataset_config['path'])
        train_dir = dataset_path / dataset_config['train']
        val_dir = dataset_path / dataset_config['val']
        
        train_images = list(train_dir.glob('*.jpg')) + list(train_dir.glob('*.png'))
        val_images = list(val_dir.glob('*.jpg')) + list(val_dir.glob('*.png'))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
        train_labels_dir = dataset_path / 'train' / 'labels'
        val_labels_dir = dataset_path / 'val' / 'labels'
        
        train_labels = list(train_labels_dir.glob('*.txt')) if train_labels_dir.exists() else []
        val_labels = list(val_labels_dir.glob('*.txt')) if val_labels_dir.exists() else []
        
        self.logger.info("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
        self.logger.info(f"  - –ö–ª–∞—Å—Å—ã: {dataset_config['nc']} ({', '.join(dataset_config['names'])})")
        self.logger.info(f"  - TRAIN: {len(train_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(train_labels)} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        self.logger.info(f"  - VAL: {len(val_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(val_labels)} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
        
        if len(train_images) == 0:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        
        if len(val_images) == 0:
            self.logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        
        self.logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–æ–π–¥–µ–Ω–∞")
        
        return dataset_config
    
    def setup_model(self, model_size: str = None) -> YOLO:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ YOLO11"""
        self.logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ YOLO11...")
        
        if model_size is None:
            model_size = self.config['model']['size']
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_name = f"yolo11{model_size}.pt"
        self.logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {model_name}")
        
        try:
            self.model = YOLO(model_name)
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
        
        # –†–∞–∑–º–µ—â–µ–Ω–∏–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        device = self.device_manager.get_device()
        self.logger.info(f"üíª –ú–æ–¥–µ–ª—å —Ä–∞–∑–º–µ—â–µ–Ω–∞ –Ω–∞: {device}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        if hasattr(self.model, 'model'):
            try:
                total_params = sum(p.numel() for p in self.model.model.parameters())
                trainable_params = sum(p.numel() for p in self.model.model.parameters() if p.requires_grad)
                
                self.logger.info("üìà –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
                self.logger.info(f"  - –í—Å–µ–≥–æ: {total_params:,}")
                self.logger.info(f"  - –û–±—É—á–∞–µ–º—ã–µ: {trainable_params:,}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö: {e}")
        
        return self.model
    
    def prepare_training_parameters(self, dataset_yaml: Path, experiment_name: str = None) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("‚öôÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è...")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        if experiment_name is None:
            timestamp = int(time.time())
            experiment_name = f"yolo_restaurant_detection_{timestamp}"
        
        self.experiment_name = experiment_name
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        experiments_dir = Path("outputs/experiments")
        self.experiment_dir = experiments_dir / experiment_name
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ batch_size
        recommended_batch = self.device_manager.get_recommended_batch_size(
            self.config['training']['batch_size']
        )
        
        if recommended_batch != self.config['training']['batch_size']:
            self.logger.info(f"üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ batch_size: "
                           f"{self.config['training']['batch_size']} ‚Üí {recommended_batch}")
            actual_batch_size = recommended_batch
        else:
            actual_batch_size = self.config['training']['batch_size']
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è YOLO
        train_params = {
            'data': str(dataset_yaml),
            'epochs': self.config['training']['epochs'],
            'batch': actual_batch_size,
            'imgsz': self.config['model']['input_size'],
            'device': self.device_manager.get_device(),
            'workers': self.config['training']['workers'],
            'project': str(self.experiment_dir.parent),
            'name': self.experiment_name,
            'exist_ok': self.config['logging']['exist_ok'],
            'verbose': self.config['logging']['verbose'],
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            'optimizer': self.config['training']['optimizer'],
            'lr0': self.config['training']['learning_rate'],
            'weight_decay': self.config['training']['weight_decay'],
            'momentum': self.config['training']['momentum'],
            'warmup_epochs': self.config['training']['warmup_epochs'],
            'warmup_momentum': self.config['training']['warmup_momentum'],
            'warmup_bias_lr': self.config['training']['warmup_bias_lr'],
            'patience': self.config['training']['patience'],
            'amp': self.config['training']['amp'],
            
            # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            'mosaic': self.config['augmentation']['mosaic'],
            'mixup': self.config['augmentation']['mixup'],
            'copy_paste': self.config['augmentation']['copy_paste'],
            'degrees': self.config['augmentation']['degrees'],
            'translate': self.config['augmentation']['translate'],
            'scale': self.config['augmentation']['scale'],
            'shear': self.config['augmentation']['shear'],
            'perspective': self.config['augmentation']['perspective'],
            'hsv_h': self.config['augmentation']['hsv_h'],
            'hsv_s': self.config['augmentation']['hsv_s'],
            'hsv_v': self.config['augmentation']['hsv_v'],
            'flipud': self.config['augmentation']['flipud'],
            'fliplr': self.config['augmentation']['fliplr'],
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            'val': True,
            'save_period': self.config['training']['save_period'],
            'plots': self.config['validation']['plots']
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_path = self.experiment_dir / 'training_config.json'
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump({
                'experiment_name': experiment_name,
                'training_config': self.config,
                'training_parameters': train_params,
                'device_info': {
                    'device': str(self.device_manager.get_device()),
                    'cuda_available': torch.cuda.is_available(),
                    'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,
                    'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3) if torch.cuda.is_available() else None
                }
            }, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_path}")
        self.logger.info(f"üìÅ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {self.experiment_dir}")
        
        return train_params
    
    def run_training(self, train_params: Dict[str, Any]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
        
        # –ü—Ä–µ–¥–æ–±—É—á–∞—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        self._pre_training_checks(train_params)
        
        # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
        self.training_stats['start_time'] = time.time()
        
        try:
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            results = self.model.train(**train_params)
            
            self.training_stats['end_time'] = time.time()
            self.training_stats['epochs_completed'] = train_params['epochs']
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            training_results = self._process_results(results)
            
            self.logger.info("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            return training_results
            
        except KeyboardInterrupt:
            self.logger.warning("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            self.training_stats['training_interrupted'] = True
            raise
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
            self.training_stats['training_interrupted'] = True
            raise
    
    def _pre_training_checks(self, train_params: Dict[str, Any]):
        """–ü—Ä–µ–¥–æ–±—É—á–∞—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        self.logger.info("üîß –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ GPU
        if torch.cuda.is_available() and train_params['device'] != 'cpu':
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            batch_size = train_params['batch']
            
            if gpu_memory < 4:
                self.logger.warning("‚ö†Ô∏è –ú–∞–ª–æ GPU –ø–∞–º—è—Ç–∏, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å batch_size")
            
            recommended_batch = self.device_manager.get_recommended_batch_size(16)
            if batch_size > recommended_batch:
                self.logger.warning(f"‚ö†Ô∏è –ë–æ–ª—å—à–æ–π batch_size: {batch_size}, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: {recommended_batch}")
        
        self.logger.info("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π forward pass —É—Å–ø–µ—à–µ–Ω")
    
    def _process_results(self, results) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        total_time = self.training_stats['end_time'] - self.training_stats['start_time']
        
        training_results = {
            'experiment_name': self.experiment_name,
            'total_training_time_seconds': total_time,
            'total_training_time_minutes': total_time / 60,
            'epochs_completed': self.training_stats['epochs_completed'],
            'device_used': str(self.device_manager.get_device()),
            'training_interrupted': self.training_stats['training_interrupted']
        }
        
        # –ü–æ–∏—Å–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        weights_dir = self.experiment_dir / 'weights'
        if weights_dir.exists():
            best_model = weights_dir / 'best.pt'
            last_model = weights_dir / 'last.pt'
            
            if best_model.exists():
                training_results['best_model_path'] = str(best_model)
                self.logger.info(f"üíé –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model}")
            
            if last_model.exists():
                training_results['last_model_path'] = str(last_model)
                self.logger.info(f"üìÑ –ü–æ—Å–ª–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å: {last_model}")
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –º–µ—Ç—Ä–∏–∫–∏
        try:
            if hasattr(results, 'results_dict'):
                metrics = results.results_dict
                training_results['final_metrics'] = metrics
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
                if 'metrics/mAP50(B)' in metrics:
                    map50 = metrics['metrics/mAP50(B)']
                    self.logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π mAP@0.5: {map50:.4f}")
                    training_results['final_map50'] = map50
                
                if 'metrics/mAP50-95(B)' in metrics:
                    map50_95 = metrics['metrics/mAP50-95(B)']
                    self.logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π mAP@0.5:0.95: {map50_95:.4f}")
                    training_results['final_map50_95'] = map50_95
        
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_path = self.experiment_dir / 'training_results.json'
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(training_results, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
        
        return training_results
    
    def train_model(self, dataset_yaml: Path, resume_from: Optional[Path] = None) -> Dict[str, Any]:
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        try:
            # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
            dataset_config = self.validate_dataset(dataset_yaml)
            
            # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏
            model = self.setup_model()
            
            # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
            train_params = self.prepare_training_parameters(dataset_yaml)
            
            # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ resume
            if resume_from and resume_from.exists():
                train_params['resume'] = str(resume_from)
                self.logger.info(f"üîÑ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å: {resume_from}")
            
            # 5. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
            results = self.run_training(train_params)
            
            # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            self._generate_final_report(results, dataset_config)
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise
    
    def _generate_final_report(self, training_results: Dict[str, Any], dataset_config: Dict[str, Any]):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        self.logger.info("\n" + "="*60)
        self.logger.info("üéØ –ò–¢–û–ì–ò –û–ë–£–ß–ï–ù–ò–Ø")
        self.logger.info("="*60)
        self.logger.info(f"üìÅ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {self.experiment_name}")
        self.logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_results.get('total_training_time_minutes', 0):.1f} –º–∏–Ω—É—Ç")
        self.logger.info(f"üîÑ –≠–ø–æ—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {training_results.get('epochs_completed', 0)}")
        self.logger.info(f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {training_results.get('device_used', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        
        if 'final_map50' in training_results:
            self.logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π mAP@0.5: {training_results['final_map50']:.4f}")
        
        if 'final_map50_95' in training_results:
            self.logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π mAP@0.5:0.95: {training_results['final_map50_95']:.4f}")
        
        if 'best_model_path' in training_results:
            self.logger.info(f"üíé –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {training_results['best_model_path']}")
        
        self.logger.info(f"üìã –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {self.experiment_dir}")
        self.logger.info("="*60)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ YOLO11 –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

1. –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ:
   python scripts/train_model.py --data data/processed/dataset/dataset.yaml

2. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ GPU:
   python scripts/train_model.py --data dataset.yaml --device cuda

3. –û–±—É—á–µ–Ω–∏–µ —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π:
   python scripts/train_model.py --data dataset.yaml --config config/train_config.json

4. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è:
   python scripts/train_model.py --data dataset.yaml --resume runs/train/exp/weights/last.pt

5. –û–±—É—á–µ–Ω–∏–µ —Å Weights & Biases:
   python scripts/train_model.py --data dataset.yaml --wandb

6. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è):
   python scripts/train_model.py --data dataset.yaml --device cpu
        """
    )
    
    parser.add_argument(
        "--data",
        type=str,
        required=True,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É dataset.yaml"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        choices=['auto', 'cpu', 'cuda', 'gpu'],
        default='auto',
        help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (auto, cpu, cuda/gpu). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: auto"
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è (JSON)"
    )
    
    parser.add_argument(
        "--resume",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è (.pt —Ñ–∞–π–ª)"
    )
    
    parser.add_argument(
        "--wandb",
        action="store_true",
        help="–í–∫–ª—é—á–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Weights & Biases"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"
    )
    
    parser.add_argument(
        "--model-size",
        type=str,
        choices=['n', 's', 'm', 'l', 'x'],
        default='n',
        help="–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ YOLO11 (n=nano, s=small, m=medium, l=large, x=xlarge). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: n"
    )
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è device –∞—Ä–≥—É–º–µ–Ω—Ç–∞
        device = args.device
        if device == 'gpu':
            device = 'cuda'
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—É—Ç–µ–π
        dataset_yaml = Path(args.data)
        config_path = Path(args.config) if args.config else None
        resume_from = Path(args.resume) if args.resume else None
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        if not dataset_yaml.exists():
            print(f"‚ùå –§–∞–π–ª dataset.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_yaml}")
            sys.exit(1)
        
        if config_path and not config_path.exists():
            print(f"‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")
            sys.exit(1)
        
        if resume_from and not resume_from.exists():
            print(f"‚ùå –§–∞–π–ª —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {resume_from}")
            sys.exit(1)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
        trainer = ProfessionalYOLOTrainer(config_path, device)
        
        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if args.model_size != 'n':
            trainer.config['model']['size'] = args.model_size
        
        # –í–∫–ª—é—á–µ–Ω–∏–µ wandb –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
        if args.wandb:
            if WANDB_AVAILABLE:
                trainer.config['logging']['wandb']['enabled'] = True
                print("üìä Weights & Biases –≤–∫–ª—é—á–µ–Ω")
            else:
                print("‚ö†Ô∏è Wandb –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install wandb")
        
        # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
        print("\n" + "="*50)
        print("üöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø YOLO11")
        print("="*50)
        print(f"üìÅ –î–∞—Ç–∞—Å–µ—Ç: {dataset_yaml}")
        print(f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        print(f"üß† –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: YOLO11{args.model_size}")
        if config_path:
            print(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_path}")
        if resume_from:
            print(f"üîÑ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å: {resume_from}")
        print("="*50)
        
        results = trainer.train_model(dataset_yaml, resume_from)
        
        if results:
            print("\n" + "="*50)
            print("üéâ –û–ë–£–ß–ï–ù–ò–ï YOLO11 –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
            print("="*50)
            
            if 'best_model_path' in results:
                print(f"üíé –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {results['best_model_path']}")
            
            if 'final_map50' in results:
                print(f"üìä mAP@0.5: {results['final_map50']:.1%}")
            
            print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {results.get('total_training_time_minutes', 0):.1f} –º–∏–Ω")
            print("\nüöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å:")
            
            if 'best_model_path' in results:
                model_path = results['best_model_path']
                print(f"   python scripts/run_inference.py --model \"{model_path}\" --input-dir \"path/to/images\"")
            
            print("="*50)
            sys.exit(0)
        else:
            print("\n‚ùå –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        print("üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        sys.exit(1)


if __name__ == "__main__":
    main()